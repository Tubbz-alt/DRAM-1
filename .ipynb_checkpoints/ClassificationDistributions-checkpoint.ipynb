{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Distributions Visualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the old DRAM model, DRAM_classify_blobs, use these settings:\n",
    "min_edge = 2,\n",
    "max_edge = 5,\n",
    "min_blobs = 1,\n",
    "max_blobs = 9,\n",
    "batch_size = 9000.\n",
    "Change analysis.py to import DRAM_classify_blobs and load the DRAM_test_square checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Setting everything up!\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from bokeh.io import push_notebook, show, output_notebook\n",
    "output_notebook()\n",
    "from bokeh.layouts import row, column\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models import ColumnDataSource, HoverTool, CustomJS, FixedTicker\n",
    "import bokeh.palettes as pal\n",
    "from bokeh.layouts import layout, Spacer, gridplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import *\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from bokeh.charts import Bar, Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis import classify_image, glimpses, read_n, classify_imgs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import scipy.special\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "\n",
    "from scipy import linspace\n",
    "from scipy import pi,sqrt,exp\n",
    "from scipy.special import erf\n",
    "import scipy\n",
    "\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.plotting import figure, show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pdf(sigma, x, mu):\n",
    "    \"\"\"Calculate the pdf.\"\"\"\n",
    "    \n",
    "#     pdf = 1/(x* sigma * np.sqrt(2*np.pi)) * np.exp(-(np.log(x)-mu)**2 / (2*sigma**2))\n",
    "    pdf = 1/(sigma * np.sqrt(2*np.pi)) * np.exp(-(x-mu)**2 / (2*sigma**2))\n",
    "    return pdf\n",
    "\n",
    "\n",
    "def get_cdf(sigma, x, mu, a):\n",
    "    \"\"\"Calculate the cdf.\"\"\"\n",
    "    \n",
    "#     cdf = (1 + erf(a*x / sqrt(2))) / 2 \n",
    "    cdf = (1 + scipy.special.erf((a*x - mu) / np.sqrt(2*sigma**2))) / 2\n",
    "    return cdf\n",
    "\n",
    "\n",
    "def get_p(pdf, cdf):\n",
    "    \"\"\"Calculate p to create skew curve.\"\"\"\n",
    "    \n",
    "    p = 2 / pdf * cdf / 100000\n",
    "    return p\n",
    "\n",
    "    \n",
    "def curve(sigma, x, mu, plot, label=\"\", color=\"gray\"):\n",
    "    \"\"\"Add normal distribution curve to plot.\"\"\"\n",
    "    \n",
    "    pdf = get_pdf(sigma, x, mu)\n",
    "    min_blobs = 1\n",
    "    plot.line(x + min_blobs, pdf, line_color=color, line_width=8, alpha=1, legend=label)\n",
    "    \n",
    "    \n",
    "def skew_curve(sigma, x, mu, a, plot):\n",
    "    \"\"\"Add a skewed curve to the plot.\"\"\"\n",
    "    \n",
    "    p = get_p(get_pdf(sigma, x, mu), get_cdf(sigma, x, mu, a))\n",
    "\n",
    "    def f(x): return 1/(sigma * np.sqrt(2*np.pi)) * np.exp(-(x-mu)**2 / (2*sigma**2))\n",
    "    max_x = scipy.optimize.fmin(lambda x: -f(x), a)\n",
    "\n",
    "    plot.line(9-x, p / f(max_x), line_color=\"blue\", line_width=8, alpha=0.4)\n",
    "    \n",
    "    \n",
    "def combined_curve(sigma, x, mu, a, plot):\n",
    "    \"\"\"Add curve combining skew and normal distribution to plot.\"\"\"\n",
    "    \n",
    "    p = get_p(get_pdf(sigma, x, mu), get_cdf(sigma, x, mu, a))\n",
    "    \n",
    "    def f(x): return 1/(sigma * np.sqrt(2*np.pi)) * np.exp(-(x-mu)**2 / (2*sigma**2))\n",
    "    max_x = scipy.optimize.fmin(lambda x: -f(x), a)\n",
    "\n",
    "    def f2(x): return (1/(sigma * np.sqrt(2*np.pi)) * np.exp(-(x-mu)**2 / (2*sigma**2)) + p / f(max_x))\n",
    "    max_x2 = scipy.optimize.fmin(lambda x: -f(x), a)\n",
    "\n",
    "    plot.line(x, (((1/(sigma * np.sqrt(2*np.pi)) * np.exp(-(x-mu)**2 / (2*sigma**2)))\n",
    "            + p / f(max_x))/ f2(max_x2)), line_color=\"purple\", line_width=2, alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_figure_colors(p, bg, fg):\n",
    "    \"\"\"Set figure p background colors bg and foreground colors fg.\"\"\"\n",
    "    \n",
    "    p.border_fill_color = bg\n",
    "    p.title.text_color = fg\n",
    "    p.xaxis.axis_label_text_color = fg\n",
    "    p.yaxis.axis_label_text_color = fg\n",
    "    p.xaxis.axis_line_color = fg\n",
    "    p.yaxis.axis_line_color = fg\n",
    "    p.xaxis.major_label_text_color = fg\n",
    "    p.yaxis.major_label_text_color = fg\n",
    "    p.xaxis.major_tick_line_color = fg\n",
    "    p.xaxis.minor_tick_line_color = fg\n",
    "    p.yaxis.major_tick_line_color = fg\n",
    "    p.yaxis.minor_tick_line_color = fg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clear_output()\n",
    "b2 = Button(description=\"Click to Start\", icon=\"arrow\", width=400)\n",
    "\n",
    "dropdown2 = Dropdown(options=['0', '1000', '2000', '3000', '4000', '5000', '10000', '20000', '30000', '40000', '50000',\n",
    "                             '60000', '70000', '80000', '90000', '100000', '110000', '120000', '130000', '140000', '150000',\n",
    "                             '160000', '170000', '180000', '190000', '200000', '250000', '300000', '400000', '500000',\n",
    "                             '600000', '700000', '800000', '900000', '910000', '920000', '1000000', '1100000', '1200000',\n",
    "                              '1300000', '1400000', '1500000'],\n",
    "                    value='100000', \n",
    "                    description='Iteration:'\n",
    ")\n",
    "\n",
    "data = None\n",
    "\n",
    "def update_curves():\n",
    "    clear_output()\n",
    "    global data\n",
    "    num_imgs = 9000\n",
    "    print(\"number of images: %d\" % num_imgs)\n",
    "    imgs_data = classify_imgs2(int(dropdown2.value), True, num_imgs)\n",
    "    \n",
    "#     num_blobs = randint(0, 9)\n",
    "    max_blobs = 9\n",
    "    min_blobs = 1\n",
    "    z_size = max_blobs - min_blobs + 1\n",
    "    \n",
    "    curves = list()\n",
    "    dark = \"#111111\"\n",
    "    light = \"#DDDDDD\"\n",
    "    p2 = figure(title=\"Blob Number Classification Probabilities Distributions\", y_range=(0, 1), tools=\"save\", background_fill_color=dark)\n",
    "    set_figure_colors(p2, dark, light)\n",
    "    confidence_one_run = np.zeros([z_size, z_size])\n",
    "    choice_one_run = np.zeros([z_size, z_size])\n",
    "\n",
    "\n",
    "    for nb in range(z_size):\n",
    "        num_blobs = nb + 1\n",
    "        print(\"number of blobs: \", num_blobs)\n",
    "        \n",
    "\n",
    "        p1 = figure(title=\"Blob Number Classification Probabilities Distribution for %d Blobs\" % num_blobs , y_range=(0, 1), tools=\"save\",\n",
    "                    background_fill_color=dark)\n",
    "        set_figure_colors(p1, dark, light)\n",
    "\n",
    "        m = 0.1\n",
    "\n",
    "        confidence_hist = np.zeros(z_size)\n",
    "        choice_hist = np.zeros(z_size)\n",
    "        value_counts = np.zeros(z_size)\n",
    "        values_sum = 0\n",
    "        sqr_sum = 0\n",
    "        num_imgs_with_num_blobs = 0\n",
    "\n",
    "        for idx, data in enumerate(imgs_data):\n",
    "\n",
    "            if data[\"label\"][(num_blobs - min_blobs)] == 1: # data is for an image with num_blobs blobs\n",
    "                num_imgs_with_num_blobs += 1\n",
    "                \n",
    "                max_glimpse = 2\n",
    "                min_glimpse = 0\n",
    "                glimpses = 10#max_glimpse - min_glimpse + 1\n",
    "                \n",
    "                for i in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]:#range(min_glimpse, max_glimpse + 1):\n",
    "                    # Histogram of softmaxes\n",
    "                    confidence_hist += data[\"classifications\"][i][0] / glimpses\n",
    "                    \n",
    "                    # Histogram of choices\n",
    "                    choice = np.argmax(data[\"classifications\"][i][0])\n",
    "                    choice_list = [0] * z_size\n",
    "                    choice_list[choice] = 1 / glimpses\n",
    "                    choice_hist += choice_list\n",
    "                    \n",
    "#                 glimpse = 1\n",
    "        \n",
    "#                 confidence_hist += data[\"classifications\"][glimpse][0]\n",
    "        \n",
    "#                 choice = np.argmax(data[\"classifications\"][glimpse][0])\n",
    "#                 choice_list = [0] * z_size\n",
    "#                 choice_list[choice] = 1\n",
    "#                 choice_hist += choice_list\n",
    "                \n",
    "        print(\"num_imgs_with_num_blobs: \", num_imgs_with_num_blobs)\n",
    "        \n",
    "        confidence_hist = confidence_hist / num_imgs_with_num_blobs\n",
    "        print(\"confidence_hist: \", confidence_hist)\n",
    "        confidence_one_run[nb] = confidence_hist.tolist()\n",
    "        \n",
    "        choice_hist = choice_hist / num_imgs_with_num_blobs\n",
    "        choice_one_run[nb] = choice_hist.tolist()\n",
    "\n",
    "        x = np.linspace(-2, 11.0, 1000)\n",
    "        source = ColumnDataSource(data=dict(color=[\"red\"] * z_size, top=confidence_hist, bottom=np.zeros(z_size), left=np.arange(min_blobs, max_blobs + 1) + m - 0.55, right=np.arange(min_blobs + 1, max_blobs + 2) - m - 0.55))\n",
    "        source2 = ColumnDataSource(data=dict(color=[\"yellow\"] * z_size, top=choice_hist, bottom=np.zeros(z_size), left=np.arange(min_blobs, max_blobs + 1) + m - 0.45, right=np.arange(min_blobs + 1, max_blobs + 2) - m - 0.45))\n",
    "        source.data[\"color\"][(num_blobs - min_blobs)] = \"lime\"\n",
    "        p1.quad('left', 'right', 'top', 'bottom', source=source, color=\"color\", alpha=1)\n",
    "        p1.quad('left', 'right', 'top', 'bottom', source=source2, color=\"color\", alpha=0.5)\n",
    "\n",
    "\n",
    "        # FORMAT PLOT ##############################\n",
    "\n",
    "        p1.xaxis.axis_label = 'Number of Blobs'\n",
    "        p1.yaxis.axis_label = 'Classification Probability'\n",
    "        p1.xaxis[0].ticker=FixedTicker(ticks=np.arange(min_blobs, max_blobs + 1))\n",
    "        \n",
    "        \n",
    "        # PLOT CURVES #############################\n",
    "        \n",
    "        # Find the mean\n",
    "        for j in range(z_size):\n",
    "            values_sum += j * choice_hist[j] # curve based on classification distribution. Use confidence_hist to get curve based on softmax.\n",
    "        mu = values_sum\n",
    "        print(\"mu: \", mu)\n",
    "\n",
    "        # Find the standard deviation\n",
    "        for k in range(z_size):\n",
    "            sqr_sum += choice_hist[k] * ((k - mu) ** 2)\n",
    "        sigma = np.sqrt(sqr_sum)\n",
    "        \n",
    "        curves.append((sigma * 2, x, mu, p2, str(num_blobs),\n",
    "                       \"#\" + str(randint(2, 9)) + str(randint(2, 9))+ str(randint(2, 9))+ str(randint(2, 9))+ str(randint(2, 9))+ str(randint(2, 9))))\n",
    "        \n",
    "        curve(sigma, x, mu, p1) # plot gaussian curve\n",
    "#         a = np.argmax(confidence_hist)\n",
    "#         skew_curve(sigma, x, mu, a, p1)\n",
    "#         combined_curve(sigma, x, mu, a, p1)\n",
    "\n",
    "        show(gridplot(p1, ncols=2, plot_width=500, plot_height=400, toolbar_location=None))\n",
    "            \n",
    "    for stats in curves:\n",
    "        curve(*stats)\n",
    "    show(p2)\n",
    "    print(\"Confidence (One Run): \")\n",
    "    print(confidence_one_run.tolist())\n",
    "    print(\"Choice (One Run): \")\n",
    "    print(choice_one_run.tolist())\n",
    "\n",
    "    \n",
    "\n",
    "def on_click2(b2, new_image=True):\n",
    "    \"\"\"Load new random image after button is clicked.\"\"\"\n",
    "    \n",
    "    b2.description = \"Loading...\"\n",
    "    update_curves()\n",
    "    b2.description = \"Next (Random) Image\"\n",
    "\n",
    "b2.on_click(on_click2)\n",
    "\n",
    "\n",
    "def on_change2(change):\n",
    "    \"\"\"Change the iteration number to new dropdown selection.\"\"\"\n",
    "    \n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        on_click(b2, new_image=False)\n",
    "        \n",
    "\n",
    "dropdown2.observe(on_change2)\n",
    "display(HBox([b2, dropdown2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
