{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py', '-f', 'true', 'true', 'true', 'true', 'true', 'model_runs/-f/count_log.csv', 'model_runs/-f/countmodel_0.ckpt', 'model_runs/-f/countmodel_', 'true', 'false', 'false', 'true']\n",
      "WARNING:tensorflow:From /home/mtfang/DRAM/COUNT_viz_onetask_nogamma.py:289: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n",
      "WARNING:tensorflow:From /home/mtfang/DRAM/COUNT_viz_onetask_nogamma.py:290: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n",
      "WARNING:tensorflow:From /home/mtfang/DRAM/COUNT_viz_onetask_nogamma.py:289: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n",
      "WARNING:tensorflow:From /home/mtfang/DRAM/COUNT_viz_onetask_nogamma.py:290: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n",
      "WARNING:tensorflow:From /home/mtfang/DRAM/COUNT_viz_onetask_nogamma.py:289: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n",
      "WARNING:tensorflow:From /home/mtfang/DRAM/COUNT_viz_onetask_nogamma.py:290: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n",
      "WARNING:tensorflow:From /home/mtfang/DRAM/COUNT_viz_onetask_nogamma.py:289: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n",
      "WARNING:tensorflow:From /home/mtfang/DRAM/COUNT_viz_onetask_nogamma.py:290: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n",
      "WARNING:tensorflow:From /home/mtfang/DRAM/COUNT_viz_onetask_nogamma.py:289: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n",
      "WARNING:tensorflow:From /home/mtfang/DRAM/COUNT_viz_onetask_nogamma.py:290: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n",
      "WARNING:tensorflow:From /home/mtfang/DRAM/COUNT_viz_onetask_nogamma.py:289: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n",
      "WARNING:tensorflow:From /home/mtfang/DRAM/COUNT_viz_onetask_nogamma.py:290: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n",
      "WARNING:tensorflow:From /home/mtfang/DRAM/COUNT_viz_onetask_nogamma.py:289: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n",
      "WARNING:tensorflow:From /home/mtfang/DRAM/COUNT_viz_onetask_nogamma.py:290: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n",
      "WARNING:tensorflow:From /home/mtfang/DRAM/COUNT_viz_onetask_nogamma.py:289: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n",
      "WARNING:tensorflow:From /home/mtfang/DRAM/COUNT_viz_onetask_nogamma.py:290: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n",
      "WARNING:tensorflow:From /home/mtfang/DRAM/COUNT_viz_onetask_nogamma.py:289: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n",
      "WARNING:tensorflow:From /home/mtfang/DRAM/COUNT_viz_onetask_nogamma.py:290: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n",
      "WARNING:tensorflow:From /home/mtfang/DRAM/COUNT_viz_onetask_nogamma.py:289: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n",
      "WARNING:tensorflow:From /home/mtfang/DRAM/COUNT_viz_onetask_nogamma.py:290: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n",
      "analysis_count_onetask.py\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "from analysis_count_onetask import read_n, classify_imgs2\n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = \"DRAM_1task_0126\"\n",
    "num_runs = 1\n",
    "iter_list = [0, 400, 800, 1600, 3200, 6400, 12800, 25600, 51200, 102400, 153600, 204800, 409600, 614400]#, 819200, 1000000, 2000000, 3000000, 4000000, 5000000, 6000000, 7000000]\n",
    "             #[0, 1000, 4000, 16000, 32000, 64000, 125000, 250000, 500000, 600000]\n",
    "#iter_list = np.arange(0,11100000,100000)\n",
    "glimpse_list = np.arange(0,10,1)\n",
    "max_blobs = 9\n",
    "min_blobs = 1\n",
    "\n",
    "num_iters = len(iter_list)\n",
    "num_glimpses = len(glimpse_list)\n",
    "blob_list = np.arange(0,10,1)\n",
    "output_size = max_blobs - min_blobs + 2 # 10\n",
    "data_directory = \"data/\" + model_name + \"/\"\n",
    "m = 0.5\n",
    "num_imgs = 9000\n",
    "confidence_all_runs = np.zeros([num_runs, num_iters, output_size-1, num_glimpses, 1, output_size]) \n",
    "choice_all_runs = np.zeros([num_runs, num_iters, output_size-1, num_glimpses, 1, output_size])\n",
    "countword_all_runs = np.zeros([num_runs, num_iters, num_imgs, output_size+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_matrix(path, iteration):\n",
    "    \"\"\"Fill the confidence and choice matrices for one run at one iteration.\"\"\"\n",
    "    \n",
    "    data = None\n",
    "    num_imgs = 9000 # batch_size\n",
    "    imgs_data = classify_imgs2(iteration, True, num_imgs, path=path) # new_imgs = True\n",
    "        \n",
    "    confidence_one_run = np.zeros([output_size-1, num_glimpses, 1, output_size])\n",
    "    choice_one_run = np.zeros([output_size-1, num_glimpses, 1, output_size])\n",
    "    countword_one_run = np.zeros([num_imgs, output_size+1])\n",
    "    \n",
    "    for nb in range(output_size-1):\n",
    "        confidence_hist = np.zeros([num_glimpses, 1, output_size])\n",
    "        choice_hist = np.zeros([num_glimpses, 1, output_size])\n",
    "        num_imgs_with_num_blobs = 0.00001\n",
    "        \n",
    "        for idx, data in enumerate(imgs_data):\n",
    "            if data[\"label\"][nb] == 1: # data is for an image with nb+1 blobs\n",
    "                num_imgs_with_num_blobs += 1\n",
    "                countword_one_run[idx][0]=nb+1\n",
    "                \n",
    "                for g, glimpse in enumerate(glimpse_list):\n",
    "                    # Histogram of softmaxes\n",
    "                    confidence_hist[glimpse] += data[\"classifications\"][glimpse]\n",
    "                    # Histogram of choices\n",
    "                    choice = np.argmax(data[\"classifications\"][glimpse])\n",
    "                    choice_list = [0] * (output_size)\n",
    "                    choice_list[choice] = 1\n",
    "                    choice_hist[glimpse] += choice_list\n",
    "                    # Count Word\n",
    "                    countword_one_run[idx][glimpse+1]=choice\n",
    "                    \n",
    "        confidence_hist = confidence_hist / num_imgs_with_num_blobs\n",
    "        confidence_one_run[nb] = confidence_hist.tolist()\n",
    "        choice_hist = choice_hist / num_imgs_with_num_blobs\n",
    "        choice_one_run[nb] = choice_hist.tolist()\n",
    "    return imgs_data, confidence_one_run, choice_one_run, countword_one_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_1task_0126_run_1/countmodel_0.ckpt\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to get matching files on model_runs/DRAM_1task_0126_run_1/countmodel_0.ckpt: Not found: model_runs/DRAM_1task_0126_run_1\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n\nCaused by op 'save/RestoreV2', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-67953e947187>\", line 5, in <module>\n    from analysis_count_onetask import read_n, classify_imgs2\n  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 673, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 665, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\n  File \"/home/mtfang/DRAM/analysis_count_onetask.py\", line 20, in <module>\n    saver = tf.train.Saver()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 1140, in __init__\n    self.build()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 1172, in build\n    filename=self._filename)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 688, in build\n    restore_sequentially, reshape)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 407, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 247, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 663, in restore_v2\n    dtypes=dtypes, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to get matching files on model_runs/DRAM_1task_0126_run_1/countmodel_0.ckpt: Not found: model_runs/DRAM_1task_0126_run_1\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to get matching files on model_runs/DRAM_1task_0126_run_1/countmodel_0.ckpt: Not found: model_runs/DRAM_1task_0126_run_1\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a1a45644bedf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#     path = 'model_runs/DRAM_test_square'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mimgs_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfidence_all_runs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchoice_all_runs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcountword_all_runs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-7fbc10475cb9>\u001b[0m in \u001b[0;36mfill_matrix\u001b[0;34m(path, iteration)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnum_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m9000\u001b[0m \u001b[0;31m# batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mimgs_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify_imgs2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# new_imgs = True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mconfidence_one_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_glimpses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DRAM/analysis_count_onetask.py\u001b[0m in \u001b[0;36mclassify_imgs2\u001b[0;34m(it, new_imgs, num_imgs, path)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhuman\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0;31m#human_cs = sess.run(classifications, feed_dict={x: imgs.reshape(num_imgs, dims[0] * dims[1])})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DRAM/analysis_count_onetask.py\u001b[0m in \u001b[0;36mload_checkpoint\u001b[0;34m(it, human, path)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhuman\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%s/countmodel_%d.ckpt\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclassify_imgs2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1558\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Restoring parameters from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1559\u001b[0m     sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1560\u001b[0;31m              {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to get matching files on model_runs/DRAM_1task_0126_run_1/countmodel_0.ckpt: Not found: model_runs/DRAM_1task_0126_run_1\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n\nCaused by op 'save/RestoreV2', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-67953e947187>\", line 5, in <module>\n    from analysis_count_onetask import read_n, classify_imgs2\n  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 673, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 665, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\n  File \"/home/mtfang/DRAM/analysis_count_onetask.py\", line 20, in <module>\n    saver = tf.train.Saver()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 1140, in __init__\n    self.build()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 1172, in build\n    filename=self._filename)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 688, in build\n    restore_sequentially, reshape)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 407, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 247, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 663, in restore_v2\n    dtypes=dtypes, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to get matching files on model_runs/DRAM_1task_0126_run_1/countmodel_0.ckpt: Not found: model_runs/DRAM_1task_0126_run_1\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n"
     ]
    }
   ],
   "source": [
    "for run in range(num_runs):\n",
    "    path = 'model_runs/' + model_name + '_run_' + str(run + 1) \n",
    "#     path = 'model_runs/DRAM_test_square'\n",
    "    for i, iteration in enumerate(iter_list):\n",
    "        imgs_data, confidence_all_runs[run, i], choice_all_runs[run, i], countword_all_runs[run, i] = fill_matrix(path, iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# COUNT WORD\n",
    "num_imgs = 9000\n",
    "confidence_one_run = np.zeros([output_size-1, num_glimpses, 1, output_size])\n",
    "choice_one_run = np.zeros([output_size-1, num_glimpses, 1, output_size])\n",
    "countword_one_run = np.zeros([num_imgs, output_size+1])\n",
    "    \n",
    "for nb in range(output_size-1):\n",
    "    confidence_hist = np.zeros([num_glimpses, 1, output_size])\n",
    "    choice_hist = np.zeros([num_glimpses, 1, output_size])\n",
    "    num_imgs_with_num_blobs = 0.00001\n",
    "        \n",
    "    for idx, data in enumerate(imgs_data):\n",
    "        if data[\"label\"][nb] == 1: # data is for an image with nb+1 blobs\n",
    "            num_imgs_with_num_blobs += 1\n",
    "            countword_one_run[idx][0]=nb+1 \n",
    "            for g, glimpse in enumerate(glimpse_list):\n",
    "                # Histogram of softmaxes\n",
    "                confidence_hist[glimpse] += data[\"classifications\"][glimpse]\n",
    "                # Histogram of choices\n",
    "                choice = np.argmax(data[\"classifications\"][glimpse])\n",
    "                countword_one_run[idx][glimpse+1]=choice\n",
    "                choice_list = [0] * (output_size)\n",
    "                choice_list[choice] = 1\n",
    "                choice_hist[glimpse] += choice_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sort_cws = np.zeros([num_runs, num_iters, num_imgs, output_size+1])\n",
    "\n",
    "for i in range(num_runs):\n",
    "    for j in range(num_iters):\n",
    "        sort_cws[i][j]=sorted(countword_all_runs[i, j, :], key = operator.itemgetter(0,1,2,3,4,5,6,7,8,9,10), reverse = False) # sorted count words\n",
    "\n",
    "stop_idx=np.ones([num_runs, num_iters, num_imgs])*(-1)\n",
    "\n",
    "for i in range(num_runs):\n",
    "    for j in range(num_iters):\n",
    "        for k in range (num_imgs):\n",
    "            for p in range (1, output_size+1):\n",
    "                if sort_cws[i][j][k][p]==0: # record end position\n",
    "                    stop_idx[i][j][k]=p\n",
    "                    break # stop at the first zero \n",
    "            \n",
    "\n",
    "results=np.zeros([num_runs, num_iters, 9, 11])  \n",
    "\n",
    "for i in range(num_runs):\n",
    "    for j in range(num_iters):\n",
    "        for k in range(num_imgs):\n",
    "            # not-well-formed\n",
    "            if stop_idx[i][j][k]==-1: # no \"I'm done!\" signal\n",
    "                results[i][j][k//1000][10]+=1\n",
    "            # all zeros\n",
    "            elif stop_idx[i][j][k]==1:\n",
    "                results[i][j][k//1000][0]+=1                \n",
    "            else:\n",
    "                for p in range(1,int(stop_idx[i][j][k])): \n",
    "                    if p!=sort_cws[i][j][k][p]:\n",
    "                        results[i][j][k//1000][10]+=1\n",
    "                        break \n",
    "                    elif p==stop_idx[i][j][k]-1:\n",
    "                        idx=int(max(sort_cws[i][j][k][1:int(stop_idx[i][j][k])+1]))\n",
    "                        results[i][j][k//1000][idx]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_count_results(run, it):\n",
    "    \"\"\"Plot the count heatmap.\"\"\"\n",
    "    matrix = np.zeros([9,11])\n",
    "    matrix = results[run, it]\n",
    "    plot_title = \"Count at Run %d after %d Iters\" % (run + 1, iter_list[it])\n",
    "    plot_count_heatmap(matrix, plot_title)\n",
    "\n",
    "def plot_count_heatmap(matrix, plot_title):\n",
    "    \"\"\"Plot heatmap.\"\"\"\n",
    "    labels_1 = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"NWF\"]\n",
    "    labels_2 = [\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]\n",
    "    data = [go.Heatmap(\n",
    "        z=matrix,\n",
    "        colorscale=\"Jet\",\n",
    "    )]\n",
    "\n",
    "    layout = go.Layout(\n",
    "        title=plot_title,\n",
    "        xaxis=dict(\n",
    "            range=[0 - m, 11 + m],\n",
    "            title=\"Count Results\",\n",
    "            #dtick=1,\n",
    "            tickangle=0,\n",
    "            ticktext=labels_1,\n",
    "            tickvals=[i * 1 for i in range(len(labels_1))],\n",
    "            tickcolor='#FFF'\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            range=[0 - m, 8 + m],\n",
    "            title=\"True Class\",\n",
    "            #dtick=1,\n",
    "            ticktext=labels_2,\n",
    "            tickvals=[i * 1 for i in range(len(labels_2))],\n",
    "            tickcolor='#FFF'\n",
    "        ),        \n",
    "        width=500,\n",
    "        height=500,\n",
    "        plot_bgcolor=\"#000\",\n",
    "        paper_bgcolor=\"#000\",\n",
    "        font=dict(\n",
    "            color=\"#FFF\"\n",
    "        ),\n",
    "        titlefont=dict(\n",
    "            color=\"#FFF\"\n",
    "        ),\n",
    "    )\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    iplot(fig)\n",
    "\n",
    "def plot_count_results(run, it):\n",
    "    \"\"\"Plot the count heatmap.\"\"\"\n",
    "    matrix = np.zeros([9,11])\n",
    "    for g in range (num_runs):\n",
    "        matrix = results[run, it]\n",
    "        plot_title = \"Count at Run %d after %d Iters\" % (run + 1, iter_list[it])\n",
    "    plot_count_heatmap(matrix, plot_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for run in range(num_runs):\n",
    "    for it in range(num_iters):\n",
    "        plot_count_results(run,it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import plotly\n",
    "plotly.tools.set_credentials_file(username='mtfang0707', api_key='18LL0DZ6dDhgqxIQ3yPQ')\n",
    "import plotly.plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "fig = ff.create_annotated_heatmap(results[0][4])\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_count_results_wv(run, it):\n",
    "    \"\"\"Plot the count heatmap with values.\"\"\"\n",
    "    data = results[run, it]\n",
    "    title = \"Count at Run %d after %d Iters\" % (run + 1, iter_list[it])\n",
    "    xlabel= \"Count Results\"\n",
    "    ylabel=\"True Class\"\n",
    "    plt.figure(figsize=(output_size+1, output_size-1))\n",
    "    plt.title(title, fontsize=20)\n",
    "    plt.xlabel(xlabel, fontsize=15)\n",
    "    plt.ylabel(ylabel, fontsize=15)\n",
    "    c = plt.pcolor(data, edgecolors='k', linewidths=2, cmap='Reds', vmin=0, vmax=1000)\n",
    "    xbars = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'NWF')\n",
    "    x_pos=[0.5,1.5,2.5,3.5,4.5,5.5,6.5,7.5,8.5,9.5,10.5]\n",
    "    plt.xticks(x_pos, xbars, fontsize='10', horizontalalignment='center')\n",
    "    ybars = ('1', '2', '3', '4', '5', '6', '7', '8', '9')\n",
    "    y_pos=[0.5,1.5,2.5,3.5,4.5,5.5,6.5,7.5,8.5]\n",
    "    plt.yticks(y_pos, ybars, fontsize='10', horizontalalignment='center')\n",
    " \n",
    "    def show_values(pc, fmt=\"%.0f\", **kw):\n",
    "        pc.update_scalarmappable()\n",
    "        ax = pc.get_axes()\n",
    "        for p, color, value in zip(pc.get_paths(), pc.get_facecolors(), pc.get_array()):\n",
    "            x, y = p.vertices[:-2, :].mean(0)\n",
    "            color = (0.0, 0.0, 0.0) # value color\n",
    "            ax.text(x, y, fmt % value, ha=\"center\", va=\"center\", color=color, **kw)\n",
    "\n",
    "    show_values(c)\n",
    "    plt.colorbar(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for run in range(num_runs):\n",
    "    for it in range(num_iters):\n",
    "        plot_count_results_wv(run,it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How high the network can count?\n",
    "high_cot = np.zeros([num_runs, num_iters]) \n",
    "\n",
    "for i in range(num_runs):\n",
    "    for j in range(num_iters):\n",
    "        for k in range (output_size-1):\n",
    "            while (results[i][j][k][k]/1000>=0.9):\n",
    "                high_cot[i][j]+=1\n",
    "\n",
    "    \n",
    "cot_accuracy/=9000\n",
    "def plot_count_accuracy(run):\n",
    "    \"\"\"Plot the only count performance.\"\"\"\n",
    "    x = iter_list\n",
    "    y = cot_accuracy[run]\n",
    "    plot_title = \"Performance of Count to 9 at Run %d\" % (run + 1)\n",
    "    plt.title(plot_title)\n",
    "    plt.plot(x, y, '.-')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Average accuracy')\n",
    "    \n",
    "results[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How high the network can count?\n",
    "high_cot = np.zeros([num_runs, num_iters]) \n",
    "\n",
    "for i in range(num_runs):\n",
    "    for j in range(num_iters):\n",
    "        for k in range (output_size-1):\n",
    "            while (results[i][j][k][k]/1000>=0.9):\n",
    "                high_cot[i][j]+=1\n",
    "\n",
    "high_cot[0,0]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adj_all_runs(all_runs_matrix):\n",
    "    \"\"\"Adjust all the matrices so tick marks start with 1.\"\"\"\n",
    "    \n",
    "    new_all_runs_matrix = np.zeros([num_runs, num_iters, output_size-1, num_glimpses+1, 1, output_size])\n",
    "    for m, matrix in enumerate(all_runs_matrix):\n",
    "        for i in range(num_iters):\n",
    "            for g in range(num_glimpses):\n",
    "                new_all_runs_matrix[m, i, g] = adj_matrix(matrix[i, g])\n",
    "    return new_all_runs_matrix\n",
    "\n",
    "\n",
    "def adj_matrix(matrix):\n",
    "    \"\"\"Adjust the matrix so tick marks start with 1.\"\"\"\n",
    "    \n",
    "    a = np.zeros([1, output_size])\n",
    "    temp = np.vstack((a, matrix))\n",
    "    b = np.zeros([output_size + 1, 1])\n",
    "    new_matrix = np.hstack((b, temp))\n",
    "    return new_matrix\n",
    "\n",
    "\n",
    "confidence_all_runs_adj = confidence_all_runs#adj_all_runs(confidence_all_runs)\n",
    "choice_all_runs_adj = choice_all_runs#adj_all_runs(choice_all_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "confidence_avg = np.mean(confidence_all_runs_adj, axis=0)\n",
    "choice_avg = np.mean(choice_all_runs_adj, axis=0)\n",
    "confidence_avg[5,0,0,0]\n",
    "np.argmax(confidence_all_runs[0,0])\n",
    "#confidence_all_runs[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confidence(iter_idx, it, num_blobs, run=None):\n",
    "    \"\"\"Plot the confidence heatmap.\"\"\"\n",
    "    \n",
    "    if run is None:\n",
    "        matrix = np.zeros([10,10])\n",
    "        for g in range (10):\n",
    "            matrix[:,g] = confidence_avg[iter_idx, num_blobs, g, 0]\n",
    "        plot_title = \"%d Blobs:Confidence after %d Iters\" % (num_blobs+1, it)\n",
    "\n",
    "    else:\n",
    "        matrix = np.zeros([10,10])\n",
    "        for g in range (10):\n",
    "            matrix = confidence_all_runs_adj[run, iter_idx, num_blobs, g, 0]\n",
    "        plot_title = \"%d Blobs:Confidence at Run %d after %d Iters\" % (num_blobs+1, run + 1, it)\n",
    "    plot_heatmap(matrix, num_blobs, plot_title)\n",
    "\n",
    "\n",
    "def plot_choice(iter_idx, it, num_blobs, run=None):\n",
    "    \"\"\"Plot the choice heatmap.\"\"\"\n",
    "    \n",
    "    if run is None:\n",
    "        matrix = np.zeros([10,10])\n",
    "        for g in range (10):\n",
    "            matrix[:,g] = choice_avg[iter_idx, num_blobs, g, 0]\n",
    "        plot_title = \"%d Blobs:Choice after %d Iterations\" % (num_blobs+1, it)\n",
    "    else:\n",
    "        matrix = np.zeros([10,10])\n",
    "        for g in range (10):\n",
    "            matrix = choice_all_runs_adj[run, iter_idx, num_blobs, g, 0]\n",
    "        plot_title = \"%d Blobs:Choice at Run %d after %d Iterations\" % (num_blobs+1, run + 1, it)\n",
    "    plot_heatmap(matrix, num_blobs, plot_title)\n",
    "    \n",
    "    \n",
    "def plot_heatmap(matrix, num_blobs, plot_title):\n",
    "    \"\"\"Plot heatmap.\"\"\"\n",
    "    \n",
    "    data = [go.Heatmap(\n",
    "        z=matrix,\n",
    "        colorscale=\"Jet\"\n",
    "    )]\n",
    "\n",
    "    layout = go.Layout(\n",
    "        title=plot_title,\n",
    "        yaxis=dict(\n",
    "#             range=[max_blobs + m, min_blobs - m],\n",
    "            range=[0 - m, 9 + m],\n",
    "            title=\"Count Word\",\n",
    "            dtick=1,\n",
    "            tickcolor='#FFF'\n",
    "        ),\n",
    "        xaxis=dict(\n",
    "            range=[0 - m, 9 + m],\n",
    "            title=\"Glimpses\",\n",
    "            dtick=1,\n",
    "            tickcolor='#FFF'\n",
    "        ),\n",
    "        width=400,\n",
    "        height=400,\n",
    "        plot_bgcolor=\"#000\",\n",
    "        paper_bgcolor=\"#000\",\n",
    "        font=dict(\n",
    "            color=\"#FFF\"\n",
    "        ),\n",
    "        titlefont=dict(\n",
    "            color=\"#FFF\"\n",
    "        ),\n",
    "    )\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#for n, num in enumerate(blob_list):\n",
    "    #for i, it in enumerate(iter_list):\n",
    "        #plot_confidence(i, it, num)\n",
    "        #plot_choice(i, it, num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for n, num in enumerate(blob_list): \n",
    "    #for i, it in enumerate(iter_list):\n",
    "    plot_confidence(0,0, num)\n",
    "    #plot_choice(i, it, num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import numpy as np\n",
    "\n",
    "F = plt.figure(1, (28,28))\n",
    "F.clf()\n",
    "\n",
    "ZS = np.zeros([num_iters*(output_size-1),10,10])\n",
    "extent = (0, 10, 0, 10) \n",
    "    \n",
    "matrix = np.zeros([10, 10])\n",
    "for num_blobs in range (output_size-1):\n",
    "    for iter_idx in range (num_iters):\n",
    "        for g in range (10):\n",
    "            matrix[:,g] = confidence_avg[iter_idx, num_blobs, g, 0]\n",
    "            ZS[iter_idx+num_iters*num_blobs] = matrix\n",
    "\n",
    "extent = extent[0], extent[1], extent[2], extent[3] \n",
    "\n",
    "grid = ImageGrid(F, 212,\n",
    "                 nrows_ncols=(output_size-1, num_iters),\n",
    "                 direction=\"row\",\n",
    "                 axes_pad=0.05,\n",
    "                 add_all=True,\n",
    "                 label_mode=\"1\",\n",
    "                 share_all=True,\n",
    "                 cbar_location=\"right\",\n",
    "                 cbar_mode=\"single\",\n",
    "                 cbar_size=\"5%\",\n",
    "                 cbar_pad=0.05,\n",
    "                 )\n",
    "\n",
    "grid[0].set_xlabel(\"Glimpse\")\n",
    "grid[0].set_ylabel(\"Count Word\")\n",
    "\n",
    "vmax, vmin = np.max(ZS), np.min(ZS)\n",
    "import matplotlib.colors\n",
    "norm = matplotlib.colors.Normalize(vmax=vmax, vmin=vmin)\n",
    "\n",
    "for ax, im_title in zip(grid, [\"iter=0\", \"400\", \"800\", \"1600\", \"3200\", \"6400\", \"12800\", \"25600\", \"51200\", \"102400\", \"153600\", \"204800\", \"307200\", \"409600\", \"614400\", \"819200\"]):\n",
    "    ax.set_title(im_title)\n",
    "    ax.patch.set_alpha(0.5)\n",
    "        \n",
    "for ax, z in zip(grid, ZS):\n",
    "    im = ax.imshow(z, norm=norm,\n",
    "                   origin=\"lower\", extent=extent,\n",
    "                   interpolation=\"nearest\")\n",
    "\n",
    "# With cbar_mode=\"single\", cax attribute of all axes are identical.\n",
    "ax.cax.colorbar(im)\n",
    "ax.cax.toggle_label(True)\n",
    "\n",
    "grid[0].set_xticks([1,2,3,4,5,6,7,8,9,10])\n",
    "grid[0].set_yticks([0,1,2,3,4,5,6,7,8,9])\n",
    "plt.draw()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
