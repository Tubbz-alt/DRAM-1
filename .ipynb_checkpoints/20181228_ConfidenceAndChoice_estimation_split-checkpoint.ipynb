{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confidence and Choice (One Layer) Visualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run DRAM_classify_blobs 10 times (use runDRAM_twolayer.sh in hydra), then copy all the checkpoints to guppy (use copyDRAM_twolayer.sh in hydra and enter password 10x).\n",
    "\n",
    "Make sure these are the <b>guppy</b> model_settings: <br />\n",
    "min_edge = 2 <br />\n",
    "max_edge = 5 <br />\n",
    "min_blobs = 1 <br />\n",
    "max_blobs = 15 (15 for training, 9 for testing)<br />\n",
    "glimpses = max_blobs + 1 <br />\n",
    "batch_size = 100\n",
    "\n",
    "You could then use this entire program or use ClassificationDistributions.ipynb to output confidence_one_run for each run, and set them as the confidence for each run in confidence_all_runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py', '-f', 'true', 'true', 'true', 'true', 'true', 'model_runs/-f/classify_log.csv', 'model_runs/-f/classifymodel_0.ckpt', 'model_runs/-f/classifymodel_', 'model_runs/-f/zzzdraw_data_5000.npy', 'false', 'true', 'false', 'false', 'true']\n",
      "WARNING:tensorflow:From /home/mtfang/DRAM/DRAMcopy13_onelayer.py:173: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n",
      "WARNING:tensorflow:From /home/mtfang/DRAM/DRAMcopy13_onelayer.py:174: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n",
      "analysis_onelayer_nds.py\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "from analysis_onelayer_nds import read_n, classify_imgs, classify_imgs_fh, classify_imgs_lh\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"DRAM_onelayer_newdata\"\n",
    "num_runs = 10\n",
    "#iter_list = [0, 250, 1000, 4000, 16000, 32000, 64000, 125000, 250000, 500000, 1000000, 1500000, 2000000, 2500000, 5000000, 7000000]\n",
    "#iter_list = [0, 1000, 10000, 250000, 500000, 1000000, 2000000, 2500000, 5000000, 8000000, 10000000, 11000000]\n",
    "#iter_list = [0, 1000, 10000, 50000, 5000000, 11000000]\n",
    "#iter_list = np.arange(0,11100000,100000)\n",
    "iter_list = [0, 400, 800, 1600, 3200, 6400, 12800, 25600, 51200, 102400, 153600, 204800, 307200, 409600, 614400, 819200, 1000000, 1228800, 1638400, 2000000]#, 2457600, 3000000]\n",
    "max_blobs = 15\n",
    "min_blobs = 1\n",
    "\n",
    "num_iters = len(iter_list)\n",
    "output_size = max_blobs - min_blobs + 1 # 15\n",
    "data_directory = \"data/\" + model_name + \"/\"\n",
    "m = 0.5\n",
    "\n",
    "confidence_all_runs_fh = np.zeros([num_runs, num_iters, output_size, output_size]) \n",
    "choice_all_runs_fh = np.zeros([num_runs, num_iters, output_size, output_size]) \n",
    "confidence_all_runs_lh = np.zeros([num_runs, num_iters, output_size, output_size]) \n",
    "choice_all_runs_lh = np.zeros([num_runs, num_iters, output_size, output_size]) \n",
    "num_iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_matrix_fh(path, iteration):\n",
    "    \"\"\"Fill the confidence and choice matrices for one run at one iteration.\"\"\"\n",
    "    \n",
    "    data = None\n",
    "    num_imgs = 9000 # batch_size\n",
    "    imgs_data = classify_imgs_fh(iteration, True, num_imgs, path=path) # new_imgs = True\n",
    "        \n",
    "    confidence_one_run = np.zeros([output_size, output_size])\n",
    "    choice_one_run = np.zeros([output_size, output_size])\n",
    "\n",
    "    for nb in range(output_size): \n",
    "        num_blobs = nb + min_blobs # 1 to 15\n",
    "        confidence_hist = np.zeros(output_size)\n",
    "        choice_hist = np.zeros(output_size)\n",
    "        num_imgs_with_num_blobs = 0.00001\n",
    "\n",
    "        for idx, data in enumerate(imgs_data):\n",
    "\n",
    "            if data[\"label\"][nb] == 1: # data is for an image with num_blobs blobs\n",
    "                num_imgs_with_num_blobs += 1\n",
    "\n",
    "                # Histogram of softmaxes\n",
    "                confidence_hist += data[\"classifications\"][0][0]\n",
    "\n",
    "                # Histogram of choices\n",
    "                choice = np.argmax(data[\"classifications\"][0][0])\n",
    "                choice_list = [0] * output_size\n",
    "                choice_list[choice] = 1\n",
    "                choice_hist += choice_list\n",
    "\n",
    "        confidence_hist = confidence_hist / num_imgs_with_num_blobs\n",
    "        confidence_one_run[nb] = confidence_hist.tolist()\n",
    "\n",
    "        choice_hist = choice_hist / num_imgs_with_num_blobs\n",
    "        choice_one_run[nb] = choice_hist.tolist()\n",
    "        \n",
    "#     print(\"Confidence (One Run): \",confidence_one_run[nb])\n",
    "#     print(confidence_one_run.tolist())\n",
    "#     print(\"Choice (One Run): \",choice_one_run[nb])\n",
    "#     print(choice_one_run.tolist())\n",
    "    return confidence_one_run, choice_one_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_1/classifymodel_0.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_1/classifymodel_400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_1/classifymodel_800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_1/classifymodel_1600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_1/classifymodel_3200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_1/classifymodel_6400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_1/classifymodel_12800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_1/classifymodel_25600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_1/classifymodel_51200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_1/classifymodel_102400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_1/classifymodel_153600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_1/classifymodel_204800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_1/classifymodel_307200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_1/classifymodel_409600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_1/classifymodel_614400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_1/classifymodel_819200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_1/classifymodel_1000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_1/classifymodel_1228800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_1/classifymodel_1638400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_1/classifymodel_2000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_2/classifymodel_0.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_2/classifymodel_400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_2/classifymodel_800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_2/classifymodel_1600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_2/classifymodel_3200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_2/classifymodel_6400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_2/classifymodel_12800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_2/classifymodel_25600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_2/classifymodel_51200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_2/classifymodel_102400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_2/classifymodel_153600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_2/classifymodel_204800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_2/classifymodel_307200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_2/classifymodel_409600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_2/classifymodel_614400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_2/classifymodel_819200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_2/classifymodel_1000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_2/classifymodel_1228800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_2/classifymodel_1638400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_2/classifymodel_2000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_3/classifymodel_0.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_3/classifymodel_400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_3/classifymodel_800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_3/classifymodel_1600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_3/classifymodel_3200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_3/classifymodel_6400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_3/classifymodel_12800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_3/classifymodel_25600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_3/classifymodel_51200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_3/classifymodel_102400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_3/classifymodel_153600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_3/classifymodel_204800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_3/classifymodel_307200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_3/classifymodel_409600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_3/classifymodel_614400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_3/classifymodel_819200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_3/classifymodel_1000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_3/classifymodel_1228800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_3/classifymodel_1638400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_3/classifymodel_2000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_4/classifymodel_0.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_4/classifymodel_400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_4/classifymodel_800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_4/classifymodel_1600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_4/classifymodel_3200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_4/classifymodel_6400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_4/classifymodel_12800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_4/classifymodel_25600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_4/classifymodel_51200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_4/classifymodel_102400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_4/classifymodel_153600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_4/classifymodel_204800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_4/classifymodel_307200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_4/classifymodel_409600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_4/classifymodel_614400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_4/classifymodel_819200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_4/classifymodel_1000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_4/classifymodel_1228800.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_4/classifymodel_1638400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_4/classifymodel_2000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_5/classifymodel_0.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_5/classifymodel_400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_5/classifymodel_800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_5/classifymodel_1600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_5/classifymodel_3200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_5/classifymodel_6400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_5/classifymodel_12800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_5/classifymodel_25600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_5/classifymodel_51200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_5/classifymodel_102400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_5/classifymodel_153600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_5/classifymodel_204800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_5/classifymodel_307200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_5/classifymodel_409600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_5/classifymodel_614400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_5/classifymodel_819200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_5/classifymodel_1000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_5/classifymodel_1228800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_5/classifymodel_1638400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_5/classifymodel_2000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_6/classifymodel_0.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_6/classifymodel_400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_6/classifymodel_800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_6/classifymodel_1600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_6/classifymodel_3200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_6/classifymodel_6400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_6/classifymodel_12800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_6/classifymodel_25600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_6/classifymodel_51200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_6/classifymodel_102400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_6/classifymodel_153600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_6/classifymodel_204800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_6/classifymodel_307200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_6/classifymodel_409600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_6/classifymodel_614400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_6/classifymodel_819200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_6/classifymodel_1000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_6/classifymodel_1228800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_6/classifymodel_1638400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_6/classifymodel_2000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_7/classifymodel_0.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_7/classifymodel_400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_7/classifymodel_800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_7/classifymodel_1600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_7/classifymodel_3200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_7/classifymodel_6400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_7/classifymodel_12800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_7/classifymodel_25600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_7/classifymodel_51200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_7/classifymodel_102400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_7/classifymodel_153600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_7/classifymodel_204800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_7/classifymodel_307200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_7/classifymodel_409600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_7/classifymodel_614400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_7/classifymodel_819200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_7/classifymodel_1000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_7/classifymodel_1228800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_7/classifymodel_1638400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_7/classifymodel_2000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_8/classifymodel_0.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_8/classifymodel_400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_8/classifymodel_800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_8/classifymodel_1600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_8/classifymodel_3200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_8/classifymodel_6400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_8/classifymodel_12800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_8/classifymodel_25600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_8/classifymodel_51200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_8/classifymodel_102400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_8/classifymodel_153600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_8/classifymodel_204800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_8/classifymodel_307200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_8/classifymodel_409600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_8/classifymodel_614400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_8/classifymodel_819200.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_8/classifymodel_1000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_8/classifymodel_1228800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_8/classifymodel_1638400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_8/classifymodel_2000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_9/classifymodel_0.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_9/classifymodel_400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_9/classifymodel_800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_9/classifymodel_1600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_9/classifymodel_3200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_9/classifymodel_6400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_9/classifymodel_12800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_9/classifymodel_25600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_9/classifymodel_51200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_9/classifymodel_102400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_9/classifymodel_153600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_9/classifymodel_204800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_9/classifymodel_307200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_9/classifymodel_409600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_9/classifymodel_614400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_9/classifymodel_819200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_9/classifymodel_1000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_9/classifymodel_1228800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_9/classifymodel_1638400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_9/classifymodel_2000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_10/classifymodel_0.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_10/classifymodel_400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_10/classifymodel_800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_10/classifymodel_1600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_10/classifymodel_3200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_10/classifymodel_6400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_10/classifymodel_12800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_10/classifymodel_25600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_10/classifymodel_51200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_10/classifymodel_102400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_10/classifymodel_153600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_10/classifymodel_204800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_10/classifymodel_307200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_10/classifymodel_409600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_10/classifymodel_614400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_10/classifymodel_819200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_10/classifymodel_1000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_10/classifymodel_1228800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_10/classifymodel_1638400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_10/classifymodel_2000000.ckpt\n"
     ]
    }
   ],
   "source": [
    "for run in range(num_runs):\n",
    "    path = 'model_runs/' + model_name + '_run_' + str(run + 1) # '/run_' if all the runs are stored in one folder\n",
    "    for i, iteration in enumerate(iter_list):\n",
    "        confidence_all_runs_fh[run, i], choice_all_runs_fh[run, i] = fill_matrix_fh(path, iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_matrix_lh(path, iteration):\n",
    "    \"\"\"Fill the confidence and choice matrices for one run at one iteration.\"\"\"\n",
    "    \n",
    "    data = None\n",
    "    num_imgs = 9000 # batch_size\n",
    "    imgs_data = classify_imgs_lh(iteration, True, num_imgs, path=path) # new_imgs = True\n",
    "        \n",
    "    confidence_one_run = np.zeros([output_size, output_size])\n",
    "    choice_one_run = np.zeros([output_size, output_size])\n",
    "\n",
    "    for nb in range(output_size): \n",
    "        num_blobs = nb + min_blobs # 1 to 15\n",
    "        confidence_hist = np.zeros(output_size)\n",
    "        choice_hist = np.zeros(output_size)\n",
    "        num_imgs_with_num_blobs = 0.00001\n",
    "\n",
    "        for idx, data in enumerate(imgs_data):\n",
    "\n",
    "            if data[\"label\"][nb] == 1: # data is for an image with num_blobs blobs\n",
    "                num_imgs_with_num_blobs += 1\n",
    "\n",
    "                # Histogram of softmaxes\n",
    "                confidence_hist += data[\"classifications\"][0][0]\n",
    "\n",
    "                # Histogram of choices\n",
    "                choice = np.argmax(data[\"classifications\"][0][0])\n",
    "                choice_list = [0] * output_size\n",
    "                choice_list[choice] = 1\n",
    "                choice_hist += choice_list\n",
    "\n",
    "        confidence_hist = confidence_hist / num_imgs_with_num_blobs\n",
    "        confidence_one_run[nb] = confidence_hist.tolist()\n",
    "\n",
    "        choice_hist = choice_hist / num_imgs_with_num_blobs\n",
    "        choice_one_run[nb] = choice_hist.tolist()\n",
    "        \n",
    "#     print(\"Confidence (One Run): \",confidence_one_run[nb])\n",
    "#     print(confidence_one_run.tolist())\n",
    "#     print(\"Choice (One Run): \",choice_one_run[nb])\n",
    "#     print(choice_one_run.tolist())\n",
    "    return confidence_one_run, choice_one_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model_runs/DRAM_onelayer_newdata_run_1/classifymodel_0.ckpt\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 4500 is out of bounds for axis 0 with size 4500",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b16bea5a38c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'model_runs/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_run_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# '/run_' if all the runs are stored in one folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mconfidence_all_runs_lh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchoice_all_runs_lh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_matrix_lh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-a78be5d6a2c7>\u001b[0m in \u001b[0;36mfill_matrix_lh\u001b[0;34m(path, iteration)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnum_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m9000\u001b[0m \u001b[0;31m# batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mimgs_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify_imgs_lh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# new_imgs = True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mconfidence_one_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DRAM/analysis_onelayer_nds.py\u001b[0m in \u001b[0;36mclassify_imgs_lh\u001b[0;34m(it, new_imgs, num_imgs, path)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0mouter_cs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner_cs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifications\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_imgs\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0mflipped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mcs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 4500 is out of bounds for axis 0 with size 4500"
     ]
    }
   ],
   "source": [
    "for run in range(num_runs):\n",
    "    path = 'model_runs/' + model_name + '_run_' + str(run + 1) # '/run_' if all the runs are stored in one folder\n",
    "    for i, iteration in enumerate(iter_list):\n",
    "        confidence_all_runs_lh[run, i], choice_all_runs_lh[run, i] = fill_matrix_lh(path, iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adj_all_runs(all_runs_matrix):\n",
    "    \"\"\"Adjust all the matrices so tick marks start with 1.\"\"\"\n",
    "    \n",
    "    new_all_runs_matrix = np.zeros([num_runs, num_iters, output_size + 1, output_size + 1])\n",
    "    for m, matrix in enumerate(all_runs_matrix):\n",
    "        for i in range(num_iters):\n",
    "            new_all_runs_matrix[m, i] = adj_matrix(matrix[i])\n",
    "    return new_all_runs_matrix\n",
    "\n",
    "\n",
    "def adj_matrix(matrix):\n",
    "    \"\"\"Adjust the matrix so tick marks start with 1.\"\"\"\n",
    "    \n",
    "    a = np.zeros([1, output_size])\n",
    "    temp = np.vstack((a, matrix))\n",
    "    b = np.zeros([output_size + 1, 1])\n",
    "    new_matrix = np.hstack((b, temp))\n",
    "    return new_matrix\n",
    "\n",
    "confidence_all_runs_adj_fh = adj_all_runs(confidence_all_runs_fh)\n",
    "choice_all_runs_adj_fh = adj_all_runs(choice_all_runs_fh)\n",
    "confidence_all_runs_adj_lh = adj_all_runs(confidence_all_runs_lh)\n",
    "choice_all_runs_adj_lh = adj_all_runs(choice_all_runs_lh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confidence_fh(iter_idx, it, run=None):\n",
    "    \"\"\"Plot the confidence heatmap.\"\"\"\n",
    "    \n",
    "    if run is None:\n",
    "        matrix = confidence_avg_fh[iter_idx]\n",
    "        plot_title = \"F: Confidence after %d Iterations\" % (it)\n",
    "\n",
    "    else:\n",
    "        matrix = confidence_all_runs_adj_fh[run, iter_idx]\n",
    "        plot_title = \"F: Confidence at Run %d after %d Iterations\" % (run + 1, it)\n",
    "    plot_heatmap(matrix, plot_title)\n",
    "\n",
    "\n",
    "def plot_choice_fh(iter_idx, it, run=None):\n",
    "    \"\"\"Plot the choice heatmap.\"\"\"\n",
    "    \n",
    "    if run is None:\n",
    "        matrix = choice_avg_fh[iter_idx]\n",
    "        plot_title = \"L: Choice after %d Iterations\" % (it)\n",
    "    else:\n",
    "        matrix = choice_all_runs_adj_fh[run, iter_idx]\n",
    "        plot_title = \"L: Choice at Run %d after %d Iterations\" % (run + 1, it)\n",
    "    plot_heatmap(matrix, plot_title)\n",
    "\n",
    "def plot_confidence_lh(iter_idx, it, run=None):\n",
    "    \"\"\"Plot the confidence heatmap.\"\"\"\n",
    "    \n",
    "    if run is None:\n",
    "        matrix = confidence_avg_lh[iter_idx]\n",
    "        plot_title = \"L: Confidence after %d Iterations\" % (it)\n",
    "\n",
    "    else:\n",
    "        matrix = confidence_all_runs_adj_lh[run, iter_idx]\n",
    "        plot_title = \"L: Confidence at Run %d after %d Iterations\" % (run + 1, it)\n",
    "    plot_heatmap(matrix, plot_title)\n",
    "\n",
    "\n",
    "def plot_choice_lh(iter_idx, it, run=None):\n",
    "    \"\"\"Plot the choice heatmap.\"\"\"\n",
    "    \n",
    "    if run is None:\n",
    "        matrix = choice_avg_lh[iter_idx]\n",
    "        plot_title = \"Choice after %d Iterations\" % (it)\n",
    "    else:\n",
    "        matrix = choice_all_runs_adj_lh[run, iter_idx]\n",
    "        plot_title = \"Choice at Run %d after %d Iterations\" % (run + 1, it)\n",
    "    plot_heatmap(matrix, plot_title)\n",
    "\n",
    "def plot_heatmap(matrix, plot_title):\n",
    "    \"\"\"Plot heatmap.\"\"\"\n",
    "    \n",
    "    data = [go.Heatmap(\n",
    "        z=matrix,\n",
    "        colorscale=\"Jet\"\n",
    "    )]\n",
    "\n",
    "    layout = go.Layout(\n",
    "        title=plot_title,\n",
    "        yaxis=dict(\n",
    "#             range=[max_blobs + m, min_blobs - m],\n",
    "            range=[9 + m, min_blobs - m],\n",
    "            title=\"True Class\",\n",
    "            dtick=1,\n",
    "            tickcolor='#FFF'\n",
    "        ),\n",
    "        xaxis=dict(\n",
    "            range=[min_blobs - m, max_blobs + m],\n",
    "            title=\"Predicted Class\",\n",
    "            dtick=1,\n",
    "            tickcolor='#FFF'\n",
    "        ),\n",
    "        width=500,\n",
    "        height=500,\n",
    "        plot_bgcolor=\"#000\",\n",
    "        paper_bgcolor=\"#000\",\n",
    "        font=dict(\n",
    "            color=\"#FFF\"\n",
    "        ),\n",
    "        titlefont=dict(\n",
    "            color=\"#FFF\"\n",
    "        ),\n",
    "    )\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, it in enumerate(iter_list):\n",
    "    #plot_confidence(i, it)\n",
    "    plot_choice_fh(i, it)\n",
    "    plot_choice_lh(i, it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for i, it in enumerate(iter_list):\n",
    "    #plot_confidence(i, it)\n",
    "    #plot_choice_lh(i, it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(data_directory + \"confidence_hist\", confidence_all_runs)\n",
    "np.save(data_directory + \"choice_hist\", choice_all_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "confidence_hist = np.load(data_directory + \"confidence_hist.npy\")\n",
    "choice_hist = np.load(data_directory + \"choice_hist.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_msdcv(hist_matrix):\n",
    "    \"\"\"Get the mean, standard deviation, and coefficient of variation matrices from histogram matrix.\"\"\"\n",
    "    \n",
    "    msdcv = np.zeros([num_runs, num_iters, output_size, 3])\n",
    "    \n",
    "    for run in range(num_runs):\n",
    "        for i, it in enumerate(iter_list):\n",
    "            for t in range(output_size):\n",
    "                values_sum = 0\n",
    "                sqr_sum = 0\n",
    "\n",
    "                # Find the mean\n",
    "                for p in range(output_size):\n",
    "                    values_sum += (p + 1) * hist_matrix[run, i, t, p]\n",
    "                msdcv[run, i, t, 0] = mu = values_sum\n",
    "\n",
    "                # Find the standard deviation\n",
    "                for p in range(output_size):\n",
    "                    sqr_sum += (p + 1 - mu)**2 * hist_matrix[run, i, t, p]\n",
    "                msdcv[run, i, t, 1] = sigma = np.sqrt(sqr_sum)\n",
    "\n",
    "                # Find the coefficient of variation\n",
    "                msdcv[run, i, t, 2] = cv = sigma / mu\n",
    "    return msdcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "confidence_msdcv = get_msdcv(confidence_hist)\n",
    "choice_msdcv = get_msdcv(choice_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(data_directory + \"confidence_msdcv\", confidence_msdcv)\n",
    "np.save(data_directory + \"choice_msdcv\", choice_msdcv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Mean, Standard Deviation, and Coefficient of Variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# chist = np.load(data_directory + \"confidence_hist.npy\")\n",
    "# cm = np.load(data_directory + \"confidence_msdv.npy\")\n",
    "chist = np.load(data_directory + \"choice_hist.npy\") # chist[run, i, output_size, output_size]\n",
    "cm = np.load(data_directory + \"choice_msdcv.npy\") # cm[run, i ,t ,3]\n",
    "cmus = cm[:,:,0:9,0] # mean\n",
    "csds = cm[:,:,0:9,1] # sd\n",
    "ccvs = cm[:,:,0:9,2] # cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chist_mu = np.mean(chist,axis=0)\n",
    "chist_min = np.min(chist,axis=0)\n",
    "chist_max = np.max(chist,axis=0)\n",
    "cmus_mu = np.mean(cmus,axis=0)\n",
    "cmus_min = np.min(cmus,axis=0)\n",
    "cmus_max = np.max(cmus,axis=0)\n",
    "csds_mu = np.mean(csds,axis=0)\n",
    "csds_min = np.min(csds,axis=0)\n",
    "csds_max = np.max(csds,axis=0)\n",
    "ccvs_mu = np.mean(ccvs,axis=0)\n",
    "ccvs_min = np.min(ccvs,axis=0)\n",
    "ccvs_max = np.max(ccvs,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# baseline\n",
    "x = [1,2,3,4,5,6,7,8,9]\n",
    "rf = np.divide(1,np.square(x)) # 1/(x^2)\n",
    "d = np.sum(rf)\n",
    "f = np.divide(rf,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_hists(i_ind):\n",
    "    mumat = chist_mu[i_ind,:,0:9]\n",
    "    minmat = chist_min[i_ind,:,0:9]\n",
    "    maxmat = chist_max[i_ind,:,0:9]\n",
    "    fig, ax = plt.subplots(9,1,sharex=True, sharey=True,figsize=(5,10))\n",
    "    x = [1,2,3,4,5,6,7,8,9]\n",
    "    fig.tight_layout()\n",
    "    plt.xticks([1,2,3,4,5,6,7,8,9])\n",
    "    tstr = 'I = ' + str(iter_list[i_ind])\n",
    "    ax[0].set_title(tstr)\n",
    "    for i in range(9):\n",
    "        ax[i].plot(x,mumat[i,:],'k-')\n",
    "        ax[i].fill_between(x,minmat[i,:],maxmat[i,:], facecolor='orange')\n",
    "        ax[i].plot(x,f)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_one_hist(run,i_ind):\n",
    "    mumat = chist[run-1,i_ind,:,0:9]\n",
    "    fig, ax = plt.subplots(9,1,sharex=True, sharey=True,figsize=(5,10))\n",
    "    x = [1,2,3,4,5,6,7,8,9]\n",
    "    fig.tight_layout()\n",
    "    plt.xticks([1,2,3,4,5,6,7,8,9])\n",
    "    tstr = 'Run = ' + str(run) + ', Iter = ' + str(iter_list[i_ind])\n",
    "    ax[0].set_title(tstr)\n",
    "    for i in range(9):\n",
    "        ax[i].plot(x,mumat[i,:],'k-')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_one_hist(1,2) # Run =1, Iter = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_hists(0) # All runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_hists(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_hists(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_hists(110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_stats(smu,smin,smax):\n",
    "    fig, ax = plt.subplots(num_iters, sharex=True, sharey=True,figsize=(5,50))\n",
    "    fig.tight_layout()\n",
    "    plt.xticks([1,2,3,4,5,6,7,8,9])\n",
    "    x = [1,2,3,4,5,6,7,8,9]\n",
    "    for i in range(num_iters):\n",
    "        tstr = 'I = ' + str(iter_list[i])\n",
    "        ax[i].set_title(tstr)\n",
    "        ax[i].plot(x,smu[i,:],'k-')\n",
    "        ax[i].fill_between(x,smin[i,:],smax[i,:], facecolor='orange')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_stats(cmus_mu,cmus_min,cmus_max) # mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_stats(csds_mu,csds_min,csds_max) # standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_stats(ccvs_mu,ccvs_min,ccvs_max) # cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# choice_avg: [num_iters, output_size, output_size]\n",
    "choice_hist = np.zeros([num_iters,10])\n",
    "for i in range (num_iters):\n",
    "    for j in range(10):\n",
    "        choice_hist[i,j] = choice_avg[i,j,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_choice_hists():\n",
    "    fig, ax = plt.subplots(9,1,sharex=True, sharey=True,figsize=(5,10))\n",
    "    x = [1,2,3,4,5,6,7,8,9]\n",
    "    fig.tight_layout()\n",
    "    plt.xticks([1,2,3,4,5,6,7,8,9])\n",
    "    #tstr = 'I = ' + str(iter_list[i_ind])\n",
    "    #ax[0].set_title(tstr)\n",
    "    for i in range(num_iters):\n",
    "        for j in range(10):\n",
    "            ax[j].plot(x,choice_hist[i,j],'k-')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "\n",
    "x = np.linspace(iter_list[0], iter_list[num_iters-1], num_iters)\n",
    "y = choice_hist[:,5]\n",
    "\n",
    "TOOLS = \"pan,wheel_zoom,box_zoom,reset,save,box_select\"\n",
    "\n",
    "p = figure(title=\"Another Legend Example\", tools=TOOLS)\n",
    "\n",
    "p.line(x, choice_hist[:,1], legend=\"1\",line_color=\"red\", line_width=3)\n",
    "p.line(x, choice_hist[:,2], legend=\"2\", line_color=\"orange\", line_width=3)\n",
    "p.line(x, choice_hist[:,3], legend=\"3\", line_color=\"yellow\", line_width=3)\n",
    "p.line(x, choice_hist[:,4], legend=\"4\", line_color=\"green\", line_width=3)\n",
    "p.line(x, choice_hist[:,5], legend=\"5\", line_color=\"blue\")\n",
    "p.line(x, choice_hist[:,6], legend=\"6\", line_color=\"purple\", line_width=3)\n",
    "p.line(x, choice_hist[:,7], legend=\"7\", line_color=\"olivedrab\", line_width=3)\n",
    "p.line(x, choice_hist[:,8], legend=\"8\", line_color=\"tomato\", line_width=3)\n",
    "p.line(x, choice_hist[:,9], legend=\"9\", line_color=\"gold\", line_width=3)\n",
    "p.xaxis.axis_label = \"Iterations\"\n",
    "p.yaxis.axis_label = \"Ave\"\n",
    "show(gridplot(p, ncols=2, plot_width=800, plot_height=800,title=\"legend.py example\"))  # open a browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
