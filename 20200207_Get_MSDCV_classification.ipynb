{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get FF_Estimation MSDCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that analysis_estimation_nds.py imports FF_estimation, and that batch_size = 100 in model_settings.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/sychen23/.local/lib/python3.5/site-packages/ipykernel_launcher.py', '-f', 'true', 'true', 'true', 'true', 'true', 'model_runs/-f/classify_log.csv', 'model_runs/-f/classifymodel_0.ckpt', 'model_runs/-f/classifymodel_', 'model_runs/-f/zzzdraw_data_5000.npy', 'false', 'true', 'false', 'false', 'true']\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/clip_ops.py:113: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "analysis_estimation_nds.py\n",
      "analysis_estimation_nds.py\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import analysis_estimation_nds\n",
    "import importlib\n",
    "importlib.reload(analysis_estimation_nds)\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style()\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [(\"New_CAA_const_fN\", \"Const Avg Area, $f(n)$ Constant\"),\n",
    "          (\"New_CAA_decrs_fN\", \"Const Avg Area, $f(n) \\propto 1/n^2$\"),\n",
    "          (\"New_DAA_const_fN\", \"Decr Avg Area, $f(n)$ Constant\"),\n",
    "          (\"New_DAA_decrs_fN\", \"Decr Avg Area, $f(n) \\propto 1/n^2$\")]\n",
    "model = models[3]\n",
    "model_name, model_figure_title = model\n",
    "num_runs = 10\n",
    "iter_list = [0, 200, 400, 1600, 6400, 25600, 102400, 204800, 409600, 819200, 1000000, 1228800, 1638400, 2000000, 3000000]#, 4000000, 5000000, 6000000]\n",
    "train_max_blobs = 15\n",
    "test_max_blobs = 9\n",
    "train_min_blobs = test_min_blobs = 1\n",
    "\n",
    "num_iters = len(iter_list)\n",
    "train_output_size = train_max_blobs - train_min_blobs + 1\n",
    "test_output_size = test_max_blobs - test_min_blobs + 1\n",
    "test_condition = \"po_ind\"\n",
    "incremental = False\n",
    "data_directory = \"data/\" + model_name + \"/\" + test_condition + \"/\"\n",
    "\n",
    "import os\n",
    "if not os.path.exists(data_directory):\n",
    "    os.makedirs(data_directory)\n",
    "    \n",
    "from pathlib import Path\n",
    "results_dir = 'Results/20200307_msdcv_3000000_classifier/confidence_msdcv/' + test_condition + \"/\"\n",
    "Path(results_dir).mkdir(parents=True, exist_ok=True)\n",
    "scalar = False\n",
    "choice = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta1_power (DT_FLOAT) []\n",
      "beta2_power (DT_FLOAT) []\n",
      "hidden/b (DT_FLOAT) [250]\n",
      "hidden/b/Adam (DT_FLOAT) [250]\n",
      "hidden/b/Adam_1 (DT_FLOAT) [250]\n",
      "hidden/w (DT_FLOAT) [225,250]\n",
      "hidden/w/Adam (DT_FLOAT) [225,250]\n",
      "hidden/w/Adam_1 (DT_FLOAT) [225,250]\n",
      "output/b (DT_FLOAT) [15]\n",
      "output/b/Adam (DT_FLOAT) [15]\n",
      "output/b/Adam_1 (DT_FLOAT) [15]\n",
      "output/w (DT_FLOAT) [250,15]\n",
      "output/w/Adam (DT_FLOAT) [250,15]\n",
      "output/w/Adam_1 (DT_FLOAT) [250,15]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.tools.inspect_checkpoint import print_tensors_in_checkpoint_file\n",
    "import os\n",
    "path = 'model_runs/' + model_name + '_run' + str(1)\n",
    "it = 0\n",
    "checkpoint_path = \"%s/classifymodel_%d.ckpt\" % (path, it)\n",
    "\n",
    "# List ALL tensors example output: v0/Adam (DT_FLOAT) [3,3,1,80]\n",
    "print_tensors_in_checkpoint_file(file_name=checkpoint_path, tensor_name='', all_tensors=False, all_tensor_names=False)\n",
    "\n",
    "# List contents of v0 tensor.\n",
    "# Example output: tensor_name:  v0 [[[[  9.27958265e-02   7.40226209e-02   4.52989563e-02   3.15700471e-02\n",
    "# print_tensors_in_checkpoint_file(file_name=checkpoint_path, tensor_name='hidden/b', all_tensors=False, all_tensor_names=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_decrs_fN_run1/classifymodel_0.ckpt\n",
      "(9,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[9.4560611e-01 3.6873417e-03 1.6616618e-02 3.4772238e-05 3.1036141e-04\n",
      " 1.8604573e-05 5.4632442e-04 2.9178970e-03 2.3236008e-02 3.2318390e-03\n",
      " 4.5662589e-04 1.0699945e-04 2.5888870e-04 2.8065261e-03 1.6501808e-04]\n"
     ]
    }
   ],
   "source": [
    "path = 'model_runs/' + model_name + '_run' + str(1)\n",
    "imgs_data = analysis_estimation_nds.classify_imgs_po(0, True, 100, path=path, incremental=incremental, scalar=scalar)\n",
    "print(np.shape(imgs_data[0]['label']))\n",
    "print(imgs_data[0]['label'])\n",
    "print(imgs_data[0]['classifications'][0]) # softmax output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classifications_one_run(path, iteration):\n",
    "    \"\"\"Get classifications for one run at one iteration.\"\"\"\n",
    "    imgs_data = analysis_estimation_nds.classify_imgs_po(iteration, True, 100, path=path, incremental=incremental, scalar=scalar)\n",
    "    confidence_one_run = np.zeros([train_output_size, train_output_size])\n",
    "    choice_one_run = np.zeros([train_output_size, train_output_size])\n",
    "\n",
    "    for nb in range(test_output_size): \n",
    "        num_blobs = nb + test_min_blobs\n",
    "        confidence_hist = np.zeros(train_output_size)\n",
    "        choice_hist = np.zeros(train_output_size)\n",
    "        num_imgs_with_num_blobs = 0.00001\n",
    "\n",
    "        for idx, data in enumerate(imgs_data):\n",
    "            if data[\"label\"][nb] == 1: # data is for an image with num_blobs blobs\n",
    "                num_imgs_with_num_blobs += 1\n",
    "\n",
    "                # Histogram of softmaxes\n",
    "                confidence_hist += np.array(data[\"classifications\"][0])\n",
    "\n",
    "                # Histogram of choices\n",
    "                choice = np.argmax(data[\"classifications\"][0])\n",
    "                choice_list = [0] * train_output_size\n",
    "                choice_list[choice] = 1\n",
    "                choice_hist += choice_list\n",
    "\n",
    "        confidence_hist = confidence_hist / num_imgs_with_num_blobs\n",
    "        confidence_one_run[nb] = confidence_hist.tolist()\n",
    "        choice_hist = choice_hist / num_imgs_with_num_blobs\n",
    "        choice_one_run[nb] = choice_hist.tolist()\n",
    "    return confidence_one_run, choice_one_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_decrs_fN_run1/classifymodel_0.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_decrs_fN_run1/classifymodel_200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_decrs_fN_run1/classifymodel_400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_decrs_fN_run1/classifymodel_1600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_decrs_fN_run1/classifymodel_6400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_decrs_fN_run1/classifymodel_25600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_decrs_fN_run1/classifymodel_102400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_decrs_fN_run1/classifymodel_204800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_decrs_fN_run1/classifymodel_409600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_decrs_fN_run1/classifymodel_819200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_decrs_fN_run1/classifymodel_1000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_decrs_fN_run1/classifymodel_1228800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_decrs_fN_run1/classifymodel_1638400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_decrs_fN_run1/classifymodel_2000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_decrs_fN_run1/classifymodel_3000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_decrs_fN_run2/classifymodel_0.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_decrs_fN_run2/classifymodel_200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_decrs_fN_run2/classifymodel_400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_decrs_fN_run2/classifymodel_1600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_decrs_fN_run2/classifymodel_6400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_decrs_fN_run2/classifymodel_25600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_decrs_fN_run2/classifymodel_102400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_decrs_fN_run2/classifymodel_204800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_decrs_fN_run2/classifymodel_409600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_decrs_fN_run2/classifymodel_819200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_decrs_fN_run2/classifymodel_1000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_decrs_fN_run2/classifymodel_1228800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_decrs_fN_run2/classifymodel_1638400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_decrs_fN_run2/classifymodel_2000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_decrs_fN_run2/classifymodel_3000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_decrs_fN_run3/classifymodel_0.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_decrs_fN_run3/classifymodel_200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_decrs_fN_run3/classifymodel_400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_decrs_fN_run3/classifymodel_1600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_decrs_fN_run3/classifymodel_6400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_decrs_fN_run3/classifymodel_25600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_decrs_fN_run3/classifymodel_102400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_decrs_fN_run3/classifymodel_204800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_decrs_fN_run3/classifymodel_409600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_decrs_fN_run3/classifymodel_819200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_decrs_fN_run3/classifymodel_1000000.ckpt\n"
     ]
    }
   ],
   "source": [
    "confidence_all_runs = np.zeros([num_runs, num_iters, train_output_size, train_output_size]) \n",
    "choice_all_runs = np.zeros([num_runs, num_iters, train_output_size, train_output_size])\n",
    "for run in range(num_runs):\n",
    "    path = 'model_runs/' + model_name + '_run' + str(run + 1) # '/run_' if all the runs are stored in one folder\n",
    "    for i, iteration in enumerate(iter_list):\n",
    "        confidence_all_runs[run, i], choice_all_runs[run, i] = get_classifications_one_run(path, iteration)\n",
    "\n",
    "np.save(data_directory + \"confidence_hist\", confidence_all_runs)\n",
    "np.save(data_directory + \"choice_hist\", choice_all_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_msdcv(hist_matrix):\n",
    "    \"\"\"Get the mean, standard deviation, and coefficient of variation matrices from histogram matrix.\"\"\"\n",
    "    \n",
    "    msdcv = np.zeros([num_runs, num_iters, train_output_size, 3])\n",
    "    \n",
    "    for run in range(num_runs):\n",
    "        for i, it in enumerate(iter_list):\n",
    "            for t in range(train_output_size):\n",
    "                values_sum = 0\n",
    "                sqr_sum = 0\n",
    "\n",
    "                # Find the mean\n",
    "                for p in range(train_output_size):\n",
    "                    values_sum += (p + 1) * hist_matrix[run, i, t, p]\n",
    "                msdcv[run, i, t, 0] = mu = values_sum\n",
    "\n",
    "                # Find the standard deviation\n",
    "                for p in range(train_output_size):\n",
    "                    sqr_sum += (p + 1 - mu)**2 * hist_matrix[run, i, t, p]\n",
    "                msdcv[run, i, t, 1] = sigma = np.sqrt(sqr_sum)\n",
    "\n",
    "                # Find the coefficient of variation\n",
    "                msdcv[run, i, t, 2] = cv = sigma / mu\n",
    "    return np.mean(msdcv, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_msdcv = get_msdcv(confidence_all_runs)\n",
    "choice_msdcv = get_msdcv(choice_all_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(data_directory + \"confidence_msdcv\", confidence_msdcv)\n",
    "np.save(data_directory + \"choice_msdcv\", choice_msdcv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Mean, Standard Deviation, and Coefficient of Variation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run 20200202_Plot_MSDCV_scalar.ipynb to get plots. Below is an example plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_iters = iter_list\n",
    "iters = [3000000]\n",
    "iter_indices = [i for i, iteration in enumerate(all_iters) if iteration in iters]\n",
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(3.7*3, 3.6))\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "plt.xticks(np.arange(test_min_blobs, test_max_blobs+1, step=1))\n",
    "ax[0].xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "ax[1].xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "ax[2].xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "numerosity = np.arange(test_min_blobs, test_max_blobs+1)\n",
    "\n",
    "ax[0].set_title(\"Mean\")\n",
    "ax[0].set_xlabel(\"Stimulus Numerosity\")\n",
    "ax[0].set_ylabel(\"Numerosity Estimate\")\n",
    "ax[0].set_yticks(np.arange(test_min_blobs, test_max_blobs+1, step=1))\n",
    "ax[0].set_xticks(np.arange(test_min_blobs, test_max_blobs+1, step=1))\n",
    "ax[0].set_prop_cycle('color',plt.cm.Spectral([val for val in np.linspace(0,1,len(iter_indices)) for _ in (0,1)]))\n",
    "\n",
    "ax[1].set_title(\"Standard Deviation\")\n",
    "ax[1].set_xlabel(\"Stimulus Numerosity\")\n",
    "ax[1].set_xticks(np.arange(test_min_blobs, test_max_blobs+1, step=1))\n",
    "ax[1].set_prop_cycle('color',plt.cm.Spectral([val for val in np.linspace(0,1,len(iter_indices)) for _ in (0,1)]))\n",
    "\n",
    "ax[2].set_title(\"Coefficient of Variation\")\n",
    "ax[2].set_xlabel(\"Stimulus Numerosity\")\n",
    "# ax[2].set_yticks(np.arange(0, 1, step=0.02))\n",
    "ax[2].set_xticks(np.arange(test_min_blobs, test_max_blobs+1, step=1))\n",
    "ax[2].set_prop_cycle('color',plt.cm.Spectral([val for val in np.linspace(0,1,len(iter_indices)) for _ in (0,1)]))\n",
    "\n",
    "for i in iter_indices:\n",
    "    mean = confidence_msdcv[i,test_min_blobs-1:test_max_blobs,0]\n",
    "    sd = confidence_msdcv[i,test_min_blobs-1:test_max_blobs,1]\n",
    "    cv = confidence_msdcv[i,test_min_blobs-1:test_max_blobs,2]\n",
    "\n",
    "    # Plot Mean.\n",
    "    ax[0].plot(numerosity, mean, label='N')\n",
    "    \n",
    "    # Plot SD.\n",
    "    ax[1].plot(numerosity, sd, label='N')\n",
    "    \n",
    "    # Plot CV.\n",
    "    ax[2].plot(numerosity, cv, label='N')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.suptitle(\"Final Performance: %s\" % model_figure_title)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "from pathlib import Path\n",
    "plt.savefig(results_dir + model_name + '.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice_msdcv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
