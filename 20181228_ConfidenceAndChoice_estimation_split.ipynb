{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confidence and Choice (One Layer) Visualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run FF_estimation 10 times (cross-reference runDRAM_twolayer.sh in hydra), then copy all the checkpoints to guppy (cross-reference copyDRAM_classify_blobs_ckpts.sh in hydra and enter password 10x).\n",
    "\n",
    "Make sure these are the <b>guppy</b> model_settings: <br />\n",
    "min_edge = 2 <br />\n",
    "max_edge = 5 <br />\n",
    "min_blobs = 1 <br />\n",
    "max_blobs = 15 (15 for training, 9 for testing)<br />\n",
    "glimpses = max_blobs + 1 <br />\n",
    "batch_size = 4500\n",
    "\n",
    "You could then use this entire program or use ClassificationDistributions.ipynb to output confidence_one_run for each run, and set them as the confidence for each run in confidence_all_runs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to change the `analysis_estimation_nds.py` file to have the correct neural network graph filename! Then, change the `model_name`, so that the correct model is restored and the data is saved in the correct directory. `iter_list` may need to be changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000\n",
      "9000\n",
      "hello sharon\n",
      "hello sharon\n",
      "hello sharon\n",
      "hello sharon\n",
      "hello sharon\n",
      "hello sharon\n",
      "hello sharon\n",
      "hello sharon\n",
      "['/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py', '-f', 'true', 'true', 'true', 'true', 'true', 'model_runs/-f/classify_log.csv', 'model_runs/-f/classifymodel_0.ckpt', 'model_runs/-f/classifymodel_', 'model_runs/-f/zzzdraw_data_5000.npy', 'false', 'true', 'false', 'false', 'true']\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/clip_ops.py:113: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "100\n",
      "numerosity: 1\n",
      "numerosity: 2\n",
      "numerosity: 3\n",
      "numerosity: 4\n",
      "numerosity: 5\n",
      "numerosity: 6\n",
      "numerosity: 7\n",
      "numerosity: 8\n",
      "numerosity: 9\n",
      "numerosity: 10\n",
      "numerosity: 11\n",
      "numerosity: 12\n",
      "numerosity: 13\n",
      "numerosity: 14\n",
      "numerosity: 15\n",
      "analysis_onelayer_nds.py\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "from analysis_estimation_nds import read_n, classify_imgs, classify_imgs_fh, classify_imgs_lh, classify_imgs_training\n",
    "from analysis_estimation_nds import classify_imgs_CTA, classify_imgs_has_spacing, classify_imgs_one_fixed\n",
    "from analysis_estimation_nds import classify_imgs_incr\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = \"New_DAA_const_fN\"\n",
    "num_runs = 10\n",
    "iter_list = [0, 200, 400, 1600, 6400, 25600, 102400, 204800, 409600, 819200, 1000000, 1228800, 1638400, 2000000, 3000000]#, 4000000, 5000000, 6000000]\n",
    "max_blobs = 15\n",
    "min_blobs = 1\n",
    "\n",
    "num_iters = len(iter_list)\n",
    "output_size = max_blobs - min_blobs + 1 # 15\n",
    "img_width = img_height = 100\n",
    "\n",
    "data_directory = \"data/\" + model_name + \"/\"\n",
    "m = 0.5\n",
    "\n",
    "confidence_all_runs_fh = np.zeros([num_runs, num_iters, output_size, output_size]) \n",
    "choice_all_runs_fh = np.zeros([num_runs, num_iters, output_size, output_size]) \n",
    "confidence_all_runs_lh = np.zeros([num_runs, num_iters, output_size, output_size]) \n",
    "choice_all_runs_lh = np.zeros([num_runs, num_iters, output_size, output_size]) \n",
    "confidence_all_runs_training = np.zeros([num_runs, num_iters, output_size, output_size]) \n",
    "choice_all_runs_training = np.zeros([num_runs, num_iters, output_size, output_size]) \n",
    "confidence_all_runs_one_fixed = np.zeros([num_runs, num_iters, output_size, output_size]) \n",
    "choice_all_runs_one_fixed = np.zeros([num_runs, num_iters, output_size, output_size])\n",
    "\n",
    "est_conf_all_runs_one_fixed = np.zeros([num_runs, num_iters, img_width, img_height]) \n",
    "est_choice_all_runs_one_fixed = np.zeros([num_runs, num_iters, img_width, img_height]) \n",
    "\n",
    "\n",
    "# See the effect of incrementing number of blobs 20191201\n",
    "num_incr = 100\n",
    "confidence_all_runs_N = np.zeros([num_runs, num_iters, output_size, output_size]) \n",
    "choice_all_runs_N = np.zeros([num_runs, num_iters, output_size, output_size])\n",
    "confidence_all_runs_N_incr = np.zeros([num_runs, num_iters, output_size, num_incr, output_size]) \n",
    "choice_all_runs_N_incr = np.zeros([num_runs, num_iters, output_size, num_incr, output_size])\n",
    "\n",
    "num_iters\n",
    "\n",
    "import os\n",
    "if not os.path.exists(data_directory):\n",
    "    os.makedirs(data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_matrix_fh(path, iteration):\n",
    "    \"\"\"Fill the confidence and choice matrices for one run at one iteration.\"\"\"\n",
    "    \n",
    "    data = None\n",
    "    num_imgs = 15000 # batch_size\n",
    "    imgs_data = classify_imgs_fh(iteration, True, num_imgs, path=path) # new_imgs = True\n",
    "        \n",
    "    confidence_one_run = np.zeros([output_size, output_size])\n",
    "    choice_one_run = np.zeros([output_size, output_size])\n",
    "\n",
    "    for nb in range(output_size): \n",
    "        num_blobs = nb + min_blobs # 1 to 15\n",
    "        confidence_hist = np.zeros(output_size)\n",
    "        choice_hist = np.zeros(output_size)\n",
    "        num_imgs_with_num_blobs = 0.00001\n",
    "\n",
    "        for idx, data in enumerate(imgs_data):\n",
    "\n",
    "            if data[\"label\"][nb] == 1: # data is for an image with num_blobs blobs\n",
    "                num_imgs_with_num_blobs += 1\n",
    "\n",
    "                # Histogram of softmaxes\n",
    "                confidence_hist += data[\"classifications\"][0][0]\n",
    "\n",
    "                # Histogram of choices\n",
    "                choice = np.argmax(data[\"classifications\"][0][0])\n",
    "                choice_list = [0] * output_size\n",
    "                choice_list[choice] = 1\n",
    "                choice_hist += choice_list\n",
    "\n",
    "        confidence_hist = confidence_hist / num_imgs_with_num_blobs\n",
    "        confidence_one_run[nb] = confidence_hist.tolist()\n",
    "\n",
    "        choice_hist = choice_hist / num_imgs_with_num_blobs\n",
    "        choice_one_run[nb] = choice_hist.tolist()\n",
    "        \n",
    "#     print(\"Confidence (One Run): \",confidence_one_run[nb])\n",
    "#     print(confidence_one_run.tolist())\n",
    "#     print(\"Choice (One Run): \",choice_one_run[nb])\n",
    "#     print(choice_one_run.tolist())\n",
    "    return confidence_one_run, choice_one_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#for run in range(num_runs):\n",
    "#    path = 'model_runs/' + model_name + '_run' + str(run + 1) # '/run_' if all the runs are stored in one folder\n",
    "#    for i, iteration in enumerate(iter_list):\n",
    "#        confidence_all_runs_fh[run, i], choice_all_runs_fh[run, i] = fill_matrix_fh(path, iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_matrix_lh(path, iteration):\n",
    "    \"\"\"Fill the confidence and choice matrices for one run at one iteration.\"\"\"\n",
    "    \n",
    "    data = None\n",
    "    num_imgs = 15000 # batch_size\n",
    "    imgs_data = classify_imgs_lh(iteration, True, num_imgs, path=path) # new_imgs = True\n",
    "        \n",
    "    confidence_one_run = np.zeros([output_size, output_size])\n",
    "    choice_one_run = np.zeros([output_size, output_size])\n",
    "\n",
    "    for nb in range(output_size): \n",
    "        num_blobs = nb + min_blobs # 1 to 15\n",
    "        confidence_hist = np.zeros(output_size)\n",
    "        choice_hist = np.zeros(output_size)\n",
    "        num_imgs_with_num_blobs = 0.00001\n",
    "\n",
    "        for idx, data in enumerate(imgs_data):\n",
    "\n",
    "            if data[\"label\"][nb] == 1: # data is for an image with num_blobs blobs\n",
    "                num_imgs_with_num_blobs += 1\n",
    "\n",
    "                # Histogram of softmaxes\n",
    "                confidence_hist += data[\"classifications\"][0][0]\n",
    "\n",
    "                # Histogram of choices\n",
    "                choice = np.argmax(data[\"classifications\"][0][0])\n",
    "                choice_list = [0] * output_size\n",
    "                choice_list[choice] = 1\n",
    "                choice_hist += choice_list\n",
    "\n",
    "        confidence_hist = confidence_hist / num_imgs_with_num_blobs\n",
    "        confidence_one_run[nb] = confidence_hist.tolist()\n",
    "\n",
    "        choice_hist = choice_hist / num_imgs_with_num_blobs\n",
    "        choice_one_run[nb] = choice_hist.tolist()\n",
    "        \n",
    "#     print(\"Confidence (One Run): \",confidence_one_run[nb])\n",
    "#     print(confidence_one_run.tolist())\n",
    "#     print(\"Choice (One Run): \",choice_one_run[nb])\n",
    "#     print(choice_one_run.tolist())\n",
    "    return confidence_one_run, choice_one_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for run in range(num_runs):\n",
    "#    path = 'model_runs/' + model_name + '_run' + str(run + 1) # '/run_' if all the runs are stored in one folder\n",
    "#    for i, iteration in enumerate(iter_list):\n",
    "#        confidence_all_runs_lh[run, i], choice_all_runs_lh[run, i] = fill_matrix_lh(path, iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_matrix_training(path, iteration):\n",
    "    \"\"\"Fill the confidence and choice matrices for one run at one iteration.\"\"\"\n",
    "    \n",
    "    data = None\n",
    "    num_imgs = 15000 # batch_size\n",
    "    imgs_data = classify_imgs_training(iteration, True, num_imgs, path=path) # new_imgs = True\n",
    "        \n",
    "    confidence_one_run = np.zeros([output_size, output_size])\n",
    "    choice_one_run = np.zeros([output_size, output_size])\n",
    "\n",
    "    for nb in range(output_size): \n",
    "        num_blobs = nb + min_blobs # 1 to 15\n",
    "        confidence_hist = np.zeros(output_size)\n",
    "        choice_hist = np.zeros(output_size)\n",
    "        num_imgs_with_num_blobs = 0.00001\n",
    "\n",
    "        for idx, data in enumerate(imgs_data):\n",
    "\n",
    "            if data[\"label\"][nb] == 1: # data is for an image with num_blobs blobs\n",
    "                num_imgs_with_num_blobs += 1\n",
    "\n",
    "                # Histogram of softmaxes\n",
    "                confidence_hist += data[\"classifications\"][0][0]\n",
    "\n",
    "                # Histogram of choices\n",
    "                choice = np.argmax(data[\"classifications\"][0][0])\n",
    "                choice_list = [0] * output_size\n",
    "                choice_list[choice] = 1\n",
    "                choice_hist += choice_list\n",
    "\n",
    "        confidence_hist = confidence_hist / num_imgs_with_num_blobs\n",
    "        confidence_one_run[nb] = confidence_hist.tolist()\n",
    "\n",
    "        choice_hist = choice_hist / num_imgs_with_num_blobs\n",
    "        choice_one_run[nb] = choice_hist.tolist()\n",
    "        \n",
    "#     print(\"Confidence (One Run): \",confidence_one_run[nb])\n",
    "#     print(confidence_one_run.tolist())\n",
    "#     print(\"Choice (One Run): \",choice_one_run[nb])\n",
    "#     print(choice_one_run.tolist())\n",
    "    return confidence_one_run, choice_one_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for run in range(num_runs):\n",
    "#     path = 'model_runs/' + model_name + '_run' + str(run + 1) # '/run_' if all the runs are stored in one folder\n",
    "#     for i, iteration in enumerate(iter_list):        \n",
    "#         confidence_all_runs_training[run, i], choice_all_runs_training[run, i] = fill_matrix_training(path, iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_expected_classification(arr):\n",
    "    running_total = 0\n",
    "    for idx, val in enumerate(arr):\n",
    "        numerosity = idx+1\n",
    "        running_total = running_total + val*numerosity\n",
    "    return running_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_matrix_one_fixed(path, iteration):\n",
    "    \"\"\"Fill the confidence and choice matrices for one run at one iteration.\"\"\"\n",
    "    \n",
    "    data = None\n",
    "    num_imgs = 10000 # batch_size\n",
    "    imgs_data = classify_imgs_one_fixed(iteration, True, num_imgs, path=path) # new_imgs = True\n",
    "        \n",
    "    confidence_one_run = np.zeros([output_size, output_size])\n",
    "    choice_one_run = np.zeros([output_size, output_size])\n",
    "\n",
    "    num_blobs = 2\n",
    "    nb = num_blobs - 1\n",
    "    confidence_hist = np.zeros(output_size)\n",
    "    choice_hist = np.zeros(output_size)\n",
    "    num_imgs_with_num_blobs = num_imgs\n",
    "    \n",
    "    est_conf_one_run = np.zeros([img_width, img_height]) #100x100 images\n",
    "    est_choice_one_run = np.zeros([img_width, img_height]) #100x100 images\n",
    "\n",
    "    for idx, data in enumerate(imgs_data):\n",
    "\n",
    "        # Histogram of softmaxes\n",
    "        confidence_hist += data[\"classifications\"][0][0]\n",
    "\n",
    "        # Histogram of choices\n",
    "        choice = np.argmax(data[\"classifications\"][0][0])\n",
    "        choice_list = [0] * output_size\n",
    "        choice_list[choice] = 1\n",
    "        choice_hist += choice_list\n",
    "                \n",
    "        # Classifications for different blob positions, graph the center coordinate of blob\n",
    "        blob_x, blob_y = data[\"blob_coords\"][idx][0], data[\"blob_coords\"][idx][1]\n",
    "        est_conf_one_run[int(blob_x)+1][int(blob_y)+1] = get_expected_classification(data[\"classifications\"][0][0])\n",
    "#         print(\"conf: %f\" % get_expected_classification(data[\"classifications\"][0][0]))\n",
    "        est_choice_one_run[int(blob_x)+1][int(blob_y)+1] = np.argmax(data[\"classifications\"][0][0])+1\n",
    "#         print(\"choice: %d\" % np.argmax(data[\"classifications\"][0][0]))\n",
    "\n",
    "    confidence_hist = confidence_hist / num_imgs_with_num_blobs\n",
    "    confidence_one_run[nb] = confidence_hist.tolist()\n",
    "\n",
    "    choice_hist = choice_hist / num_imgs_with_num_blobs\n",
    "    choice_one_run[nb] = choice_hist.tolist()\n",
    "        \n",
    "#     print(\"Confidence (One Run): \",confidence_one_run[nb])\n",
    "#     print(confidence_one_run.tolist())\n",
    "#     print(\"Choice (One Run): \",choice_one_run[nb])\n",
    "#     print(choice_one_run.tolist())\n",
    "    return confidence_one_run, choice_one_run, est_conf_one_run, est_choice_one_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.randint(1, 99-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for run in range(num_runs):\n",
    "#     path = 'model_runs/' + model_name + '_run' + str(run + 1) # '/run_' if all the runs are stored in one folder\n",
    "#     for i, iteration in enumerate(iter_list):\n",
    "#         confidence_all_runs_one_fixed[run, i], choice_all_runs_one_fixed[run, i], est_conf_all_runs_one_fixed[run, i], est_choice_all_runs_one_fixed[run, i] = fill_matrix_one_fixed(path, iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_matrix_incr(path, iteration):\n",
    "    \"\"\"Fill the confidence and choice matrices for one run at one iteration.\"\"\"\n",
    "    \n",
    "    data = None\n",
    "    num_imgs = 100\n",
    "    num_incr = 100\n",
    "    imgs_data_all_N = classify_imgs_incr(iteration, False, path=path) # new_imgs = False\n",
    "    \n",
    "    confidence_one_run_N = np.zeros([output_size, output_size])\n",
    "    choice_one_run_N = np.zeros([output_size, output_size])\n",
    "    confidence_one_run_N_incr = np.zeros([output_size, num_incr, output_size])\n",
    "    choice_one_run_N_incr = np.zeros([output_size, num_incr, output_size])\n",
    "    \n",
    "    num_imgs_with_num_blobs = num_imgs\n",
    "\n",
    "    for n, imgs_data in enumerate(imgs_data_all_N):\n",
    "#         print('n: %d' % n)\n",
    "        \n",
    "        confidence_hist = np.zeros(output_size)\n",
    "        choice_hist = np.zeros(output_size)\n",
    "        \n",
    "        for idx, data in enumerate(imgs_data):\n",
    "            # Histogram of softmaxes\n",
    "            confidence_hist += data[\"classifications\"][0]\n",
    "\n",
    "            # Histogram of choices\n",
    "            choice = np.argmax(data[\"classifications\"][0])\n",
    "            choice_list = [0] * output_size\n",
    "            choice_list[choice] = 1\n",
    "            choice_hist += choice_list\n",
    "            \n",
    "            # Get all the data from the images with N+1 blobs\n",
    "            confidence_hist_for_img_incr = np.zeros(output_size)\n",
    "            confidence_hist_for_img = np.zeros(output_size)\n",
    "            choice_hist_for_img = np.zeros(output_size)\n",
    "            for cs_idx, cs in enumerate(data[\"classifications_incr\"]):\n",
    "                \n",
    "                # Histogram of softmaxes\n",
    "                confidence_hist_for_img += cs[0]\n",
    "                \n",
    "                # Histogram of choices\n",
    "                choice_for_img = np.argmax(cs[0])\n",
    "                choice_list_for_img = [0] * output_size\n",
    "                choice_list_for_img[choice_for_img] = 1\n",
    "                choice_hist_for_img += choice_list\n",
    "                \n",
    "            confidence_hist_for_img = confidence_hist_for_img / num_imgs_with_num_blobs\n",
    "#             print('confidence_hist_for_img:')\n",
    "#             print(confidence_hist_for_img)\n",
    "#             print('sum(confidence_hist_for_img):')\n",
    "#             print(sum(confidence_hist_for_img))\n",
    "#             print('np.argmax(confidence_hist_for_img):')\n",
    "#             print(np.argmax(confidence_hist_for_img))\n",
    "            confidence_one_run_N_incr[n][idx] = confidence_hist_for_img.tolist()\n",
    "\n",
    "            choice_hist_for_img = choice_for_img / num_imgs_with_num_blobs\n",
    "            choice_one_run_N_incr[n][idx] = choice_hist_for_img.tolist()\n",
    "\n",
    "        confidence_hist = confidence_hist / num_imgs_with_num_blobs\n",
    "        confidence_one_run_N[n] = confidence_hist.tolist()\n",
    "\n",
    "        choice_hist = choice_hist / num_imgs_with_num_blobs\n",
    "        choice_one_run_N[n] = choice_hist.tolist()\n",
    "        \n",
    "#     print(\"Confidence (One Run): \",confidence_one_run[nb])\n",
    "#     print(confidence_one_run.tolist())\n",
    "#     print(\"Choice (One Run): \",choice_one_run[nb])\n",
    "#     print(choice_one_run.tolist())\n",
    "\n",
    "    return confidence_one_run_N, choice_one_run_N, confidence_one_run_N_incr, choice_one_run_N_incr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run3/classifymodel_3000000.ckpt\n"
     ]
    }
   ],
   "source": [
    "run = 2\n",
    "path = 'model_runs/' + model_name + '_run' + str(run + 1) # '/run_' if all the runs are stored in one folder\n",
    "sharon1, sharon2, sharon3, sharon4 = fill_matrix_incr(path, 3000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run1/classifymodel_0.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run1/classifymodel_200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run1/classifymodel_400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run1/classifymodel_1600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run1/classifymodel_6400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run1/classifymodel_25600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run1/classifymodel_102400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run1/classifymodel_204800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run1/classifymodel_409600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run1/classifymodel_819200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run1/classifymodel_1000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run1/classifymodel_1228800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run1/classifymodel_1638400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run1/classifymodel_2000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run1/classifymodel_3000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run2/classifymodel_0.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run2/classifymodel_200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run2/classifymodel_400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run2/classifymodel_1600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run2/classifymodel_6400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run2/classifymodel_25600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run2/classifymodel_102400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run2/classifymodel_204800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run2/classifymodel_409600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run2/classifymodel_819200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run2/classifymodel_1000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run2/classifymodel_1228800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run2/classifymodel_1638400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run2/classifymodel_2000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run2/classifymodel_3000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run3/classifymodel_0.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run3/classifymodel_200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run3/classifymodel_400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run3/classifymodel_1600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run3/classifymodel_6400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run3/classifymodel_25600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run3/classifymodel_102400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run3/classifymodel_204800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run3/classifymodel_409600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run3/classifymodel_819200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run3/classifymodel_1000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run3/classifymodel_1228800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run3/classifymodel_1638400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run3/classifymodel_2000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run3/classifymodel_3000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run4/classifymodel_0.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run4/classifymodel_200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run4/classifymodel_400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run4/classifymodel_1600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run4/classifymodel_6400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run4/classifymodel_25600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run4/classifymodel_102400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run4/classifymodel_204800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run4/classifymodel_409600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run4/classifymodel_819200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run4/classifymodel_1000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run4/classifymodel_1228800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run4/classifymodel_1638400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run4/classifymodel_2000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run4/classifymodel_3000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run5/classifymodel_0.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run5/classifymodel_200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run5/classifymodel_400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run5/classifymodel_1600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run5/classifymodel_6400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run5/classifymodel_25600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run5/classifymodel_102400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run5/classifymodel_204800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run5/classifymodel_409600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run5/classifymodel_819200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run5/classifymodel_1000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run5/classifymodel_1228800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run5/classifymodel_1638400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run5/classifymodel_2000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run5/classifymodel_3000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run6/classifymodel_0.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run6/classifymodel_200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run6/classifymodel_400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run6/classifymodel_1600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run6/classifymodel_6400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run6/classifymodel_25600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run6/classifymodel_102400.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run6/classifymodel_204800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run6/classifymodel_409600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run6/classifymodel_819200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run6/classifymodel_1000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run6/classifymodel_1228800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run6/classifymodel_1638400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run6/classifymodel_2000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run6/classifymodel_3000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run7/classifymodel_0.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run7/classifymodel_200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run7/classifymodel_400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run7/classifymodel_1600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run7/classifymodel_6400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run7/classifymodel_25600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run7/classifymodel_102400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run7/classifymodel_204800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run7/classifymodel_409600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run7/classifymodel_819200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run7/classifymodel_1000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run7/classifymodel_1228800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run7/classifymodel_1638400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run7/classifymodel_2000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run7/classifymodel_3000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run8/classifymodel_0.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run8/classifymodel_200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run8/classifymodel_400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run8/classifymodel_1600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run8/classifymodel_6400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run8/classifymodel_25600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run8/classifymodel_102400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run8/classifymodel_204800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run8/classifymodel_409600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run8/classifymodel_819200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run8/classifymodel_1000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run8/classifymodel_1228800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run8/classifymodel_1638400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run8/classifymodel_2000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run8/classifymodel_3000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run9/classifymodel_0.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run9/classifymodel_200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run9/classifymodel_400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run9/classifymodel_1600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run9/classifymodel_6400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run9/classifymodel_25600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run9/classifymodel_102400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run9/classifymodel_204800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run9/classifymodel_409600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run9/classifymodel_819200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run9/classifymodel_1000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run9/classifymodel_1228800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run9/classifymodel_1638400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run9/classifymodel_2000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run9/classifymodel_3000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run10/classifymodel_0.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run10/classifymodel_200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run10/classifymodel_400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run10/classifymodel_1600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run10/classifymodel_6400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run10/classifymodel_25600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run10/classifymodel_102400.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run10/classifymodel_204800.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run10/classifymodel_409600.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run10/classifymodel_819200.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run10/classifymodel_1000000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_runs/New_DAA_const_fN_run10/classifymodel_1228800.ckpt\n"
     ]
    }
   ],
   "source": [
    "for run in range(num_runs):\n",
    "    path = 'model_runs/' + model_name + '_run' + str(run + 1) # '/run_' if all the runs are stored in one folder\n",
    "    for i, iteration in enumerate(iter_list):\n",
    "        # See the effect of incrementing number of blobs 20191201\n",
    "        confidence_all_runs_N[run, i], choice_all_runs_N[run, i], confidence_all_runs_N_incr[run, i], choice_all_runs_N_incr[run, i] = fill_matrix_incr(path, iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice_all_runs_N_incr[9][9][0] # 10x15x9x9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adj_all_runs(all_runs_matrix):\n",
    "    \"\"\"Adjust all the matrices so tick marks start with 1.\"\"\"\n",
    "    \n",
    "    new_all_runs_matrix = np.zeros([num_runs, num_iters, output_size + 1, output_size + 1])\n",
    "    for m, matrix in enumerate(all_runs_matrix):\n",
    "        for i in range(num_iters):\n",
    "            new_all_runs_matrix[m, i] = adj_matrix(matrix[i])\n",
    "    return new_all_runs_matrix\n",
    "\n",
    "\n",
    "def adj_matrix(matrix):\n",
    "    \"\"\"Adjust the matrix so tick marks start with 1.\"\"\"\n",
    "    \n",
    "    a = np.zeros([1, output_size])\n",
    "    temp = np.vstack((a, matrix))\n",
    "    b = np.zeros([output_size + 1, 1])\n",
    "    new_matrix = np.hstack((b, temp))\n",
    "    return new_matrix\n",
    "\n",
    "#confidence_all_runs_adj_fh = adj_all_runs(confidence_all_runs_fh)\n",
    "#choice_all_runs_adj_fh = adj_all_runs(choice_all_runs_fh)\n",
    "#confidence_all_runs_adj_lh = adj_all_runs(confidence_all_runs_lh)\n",
    "#choice_all_runs_adj_lh = adj_all_runs(choice_all_runs_lh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#confidence_all_runs_adj_training = adj_all_runs(confidence_all_runs_training)\n",
    "#choice_all_runs_adj_training = adj_all_runs(choice_all_runs_training)\n",
    "# confidence_all_runs_adj_one_fixed = adj_all_runs(confidence_all_runs_one_fixed)\n",
    "# choice_all_runs_adj_one_fixed = adj_all_runs(confidence_all_runs_N)\n",
    "confidence_all_runs_adj_N = adj_all_runs(confidence_all_runs_N)\n",
    "choice_all_runs_adj_N = adj_all_runs(choice_all_runs_N)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#confidence_avg_fh = np.mean(confidence_all_runs_adj_fh, axis=0)\n",
    "#choice_avg_fh = np.mean(choice_all_runs_adj_fh, axis=0)\n",
    "#confidence_avg_lh = np.mean(confidence_all_runs_adj_lh, axis=0)\n",
    "#choice_avg_lh = np.mean(choice_all_runs_adj_lh, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#confidence_avg_training = np.mean(confidence_all_runs_adj_training, axis=0)\n",
    "#choice_avg_training = np.mean(choice_all_runs_adj_training, axis=0)\n",
    "# confidence_avg_one_fixed = np.mean(confidence_all_runs_adj_one_fixed, axis=0)\n",
    "# choice_avg_one_fixed = np.mean(choice_all_runs_adj_one_fixed, axis=0)\n",
    "confidence_avg_N = np.mean(confidence_all_runs_adj_N, axis=0)\n",
    "choice_avg_N = np.mean(choice_all_runs_adj_N, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confidence_fh(iter_idx, it, run=None):\n",
    "    \"\"\"Plot the confidence heatmap.\"\"\"\n",
    "    \n",
    "    if run is None:\n",
    "        matrix = confidence_avg_fh[iter_idx]\n",
    "        plot_title = \"F500: Confidence after %d Iterations\" % (it)\n",
    "\n",
    "    else:\n",
    "        matrix = confidence_all_runs_adj_fh[run, iter_idx]\n",
    "        plot_title = \"F500: Confidence at Run %d after %d Iterations\" % (run + 1, it)\n",
    "    plot_heatmap(matrix, plot_title)\n",
    "\n",
    "\n",
    "def plot_choice_fh(iter_idx, it, run=None):\n",
    "    \"\"\"Plot the choice heatmap.\"\"\"\n",
    "    \n",
    "    if run is None:\n",
    "        matrix = choice_avg_fh[iter_idx]\n",
    "        plot_title = \"F500: Choice after %d Iterations\" % (it)\n",
    "    else:\n",
    "        matrix = choice_all_runs_adj_fh[run, iter_idx]\n",
    "        plot_title = \"F500: Choice at Run %d after %d Iterations\" % (run + 1, it)\n",
    "    plot_heatmap(matrix, plot_title)\n",
    "\n",
    "def plot_confidence_lh(iter_idx, it, run=None):\n",
    "    \"\"\"Plot the confidence heatmap.\"\"\"\n",
    "    \n",
    "    if run is None:\n",
    "        matrix = confidence_avg_lh[iter_idx]\n",
    "        plot_title = \"L500: Confidence after %d Iterations\" % (it)\n",
    "\n",
    "    else:\n",
    "        matrix = confidence_all_runs_adj_lh[run, iter_idx]\n",
    "        plot_title = \"L500: Confidence at Run %d after %d Iterations\" % (run + 1, it)\n",
    "    plot_heatmap(matrix, plot_title)\n",
    "\n",
    "\n",
    "def plot_choice_lh(iter_idx, it, run=None):\n",
    "    \"\"\"Plot the choice heatmap.\"\"\"\n",
    "    \n",
    "    if run is None:\n",
    "        matrix = choice_avg_lh[iter_idx]\n",
    "        plot_title = \"L500: Choice after %d Iterations\" % (it)\n",
    "    else:\n",
    "        matrix = choice_all_runs_adj_lh[run, iter_idx]\n",
    "        plot_title = \"L500: Choice at Run %d after %d Iterations\" % (run + 1, it)\n",
    "    plot_heatmap(matrix, plot_title)\n",
    "\n",
    "def plot_heatmap(matrix, plot_title):\n",
    "    \"\"\"Plot heatmap.\"\"\"\n",
    "    \n",
    "    data = [go.Heatmap(\n",
    "        z=matrix,\n",
    "        colorscale=\"Jet\"\n",
    "    )]\n",
    "\n",
    "    layout = go.Layout(\n",
    "        title=plot_title,\n",
    "        yaxis=dict(\n",
    "#             range=[max_blobs + m, min_blobs - m],\n",
    "            range=[9 + m, min_blobs - m],\n",
    "            title=\"True Class\",\n",
    "            dtick=1,\n",
    "            tickcolor='#FFF'\n",
    "        ),\n",
    "        xaxis=dict(\n",
    "            range=[min_blobs - m, max_blobs + m],\n",
    "            title=\"Predicted Class\",\n",
    "            dtick=1,\n",
    "            tickcolor='#FFF'\n",
    "        ),\n",
    "        width=500,\n",
    "        height=500,\n",
    "        plot_bgcolor=\"#000\",\n",
    "        paper_bgcolor=\"#000\",\n",
    "        font=dict(\n",
    "            color=\"#FFF\"\n",
    "        ),\n",
    "        titlefont=dict(\n",
    "            color=\"#FFF\"\n",
    "        ),\n",
    "    )\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i, it in enumerate(iter_list):\n",
    "    #plot_confidence_lh(i, it)\n",
    "    #plot_confidence_lh(i, it)\n",
    "    #plot_choice_fh(i, it)\n",
    "    #plot_choice_lh(i, it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for i, it in enumerate(iter_list):\n",
    "    #plot_confidence(i, it)\n",
    "    #plot_choice_lh(i, it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#np.save(data_directory + \"confidence_hist_fh\", confidence_all_runs_fh)\n",
    "#np.save(data_directory + \"choice_hist_fh\", choice_all_runs_fh)\n",
    "#np.save(data_directory + \"confidence_hist_lh\", confidence_all_runs_lh)\n",
    "#np.save(data_directory + \"choice_hist_lh\", choice_all_runs_lh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#np.save(data_directory + \"confidence_hist_training\", confidence_all_runs_training)\n",
    "#np.save(data_directory + \"choice_hist_training\", choice_all_runs_training)\n",
    "# np.save(data_directory + \"confidence_hist_one_fixed_span\", confidence_all_runs_one_fixed)\n",
    "# np.save(data_directory + \"choice_hist_one_fixed_span\", choice_all_runs_one_fixed)\n",
    "np.save(data_directory + \"confidence_hist_N\", confidence_all_runs_N)\n",
    "np.save(data_directory + \"choice_hist_N\", choice_all_runs_N)\n",
    "np.save(data_directory + \"confidence_hist_N_incr\", confidence_all_runs_N_incr)\n",
    "np.save(data_directory + \"choice_hist_N_incr\", choice_all_runs_N_incr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#confidence_hist_fh = np.load(data_directory + \"confidence_hist_fh.npy\")\n",
    "#choice_hist_fh = np.load(data_directory + \"choice_hist_fh.npy\")\n",
    "#confidence_hist_lh = np.load(data_directory + \"confidence_hist_lh.npy\")\n",
    "#choice_hist_lh = np.load(data_directory + \"choice_hist_lh.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#confidence_hist_training = np.load(data_directory + \"confidence_hist_training.npy\")\n",
    "#choice_hist_training = np.load(data_directory + \"choice_hist_training.npy\")\n",
    "# confidence_hist_one_fixed = np.load(data_directory + \"confidence_hist_one_fixed_span.npy\")\n",
    "# choice_hist_one_fixed = np.load(data_directory + \"choice_hist_one_fixed_span.npy\")\n",
    "confidence_hist_N = np.load(data_directory + \"confidence_hist_N.npy\")\n",
    "choice_hist_N = np.load(data_directory + \"choice_hist_N.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_msdcv(hist_matrix):\n",
    "    \"\"\"Get the mean, standard deviation, and coefficient of variation matrices from histogram matrix.\"\"\"\n",
    "    \n",
    "    msdcv = np.zeros([num_runs, num_iters, output_size, 3])\n",
    "    \n",
    "    for run in range(num_runs):\n",
    "        for i, it in enumerate(iter_list):\n",
    "            for t in range(output_size):\n",
    "                values_sum = 0\n",
    "                sqr_sum = 0\n",
    "\n",
    "                # Find the mean\n",
    "                for p in range(output_size):\n",
    "                    values_sum += (p + 1) * hist_matrix[run, i, t, p]\n",
    "                msdcv[run, i, t, 0] = mu = values_sum\n",
    "\n",
    "                # Find the standard deviation\n",
    "                for p in range(output_size):\n",
    "                    sqr_sum += (p + 1 - mu)**2 * hist_matrix[run, i, t, p]\n",
    "                msdcv[run, i, t, 1] = sigma = np.sqrt(sqr_sum)\n",
    "\n",
    "                # Find the coefficient of variation\n",
    "                msdcv[run, i, t, 2] = cv = sigma / mu\n",
    "    return msdcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#confidence_msdcv_fh = get_msdcv(confidence_hist_fh)\n",
    "#choice_msdcv_fh = get_msdcv(choice_hist_fh)\n",
    "#confidence_msdcv_lh = get_msdcv(confidence_hist_lh)\n",
    "#choice_msdcv_lh = get_msdcv(choice_hist_lh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#confidence_msdcv_training = get_msdcv(confidence_hist_training)\n",
    "#choice_msdcv_training = get_msdcv(choice_hist_training)\n",
    "# confidence_msdcv_one_fixed = get_msdcv(confidence_hist_one_fixed)\n",
    "# choice_msdcv_one_fixed = get_msdcv(choice_hist_one_fixed)\n",
    "confidence_msdcv_N = get_msdcv(confidence_hist_N)\n",
    "choice_msdcv_N = get_msdcv(choice_hist_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#np.save(data_directory + \"confidence_msdcv_fh\", confidence_msdcv_fh)\n",
    "#np.save(data_directory + \"choice_msdcv_fh\", choice_msdcv_fh)\n",
    "#np.save(data_directory + \"confidence_msdcv_lh\", confidence_msdcv_lh)\n",
    "#np.save(data_directory + \"choice_msdcv_lh\", choice_msdcv_lh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#np.save(data_directory + \"confidence_msdcv_training\", confidence_msdcv_training)\n",
    "#np.save(data_directory + \"choice_msdcv_training\", choice_msdcv_training)\n",
    "np.save(data_directory + \"confidence_msdcv_N\", confidence_msdcv_N)\n",
    "np.save(data_directory + \"choice_msdcv_N\", choice_msdcv_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# One Fixed Blob Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# est_conf_avg_one_fixed = np.mean(est_conf_all_runs_one_fixed, axis=0)\n",
    "# est_choice_avg_one_fixed = np.mean(est_choice_all_runs_one_fixed, axis=0)\n",
    "# np.save(data_directory + \"est_conf_avg_one_fixed_span\", est_conf_avg_one_fixed)\n",
    "# np.save(data_directory + \"est_choice_avg_one_fixed_span\", est_choice_avg_one_fixed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Mean, Standard Deviation, and Coefficient of Variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# chist = np.load(data_directory + \"confidence_hist.npy\")\n",
    "# cm = np.load(data_directory + \"confidence_msdv.npy\")\n",
    "chist = np.load(data_directory + \"choice_hist_N.npy\") # chist[run, i, output_size, output_size]\n",
    "cm = np.load(data_directory + \"choice_msdcv_N.npy\") # cm[run, i ,t ,3]\n",
    "cmus = cm[:,:,0:9,0] # mean\n",
    "csds = cm[:,:,0:9,1] # sd\n",
    "ccvs = cm[:,:,0:9,2] # cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chist_mu = np.mean(chist,axis=0)\n",
    "chist_min = np.min(chist,axis=0)\n",
    "chist_max = np.max(chist,axis=0)\n",
    "cmus_mu = np.mean(cmus,axis=0)\n",
    "cmus_min = np.min(cmus,axis=0)\n",
    "cmus_max = np.max(cmus,axis=0)\n",
    "csds_mu = np.mean(csds,axis=0)\n",
    "csds_min = np.min(csds,axis=0)\n",
    "csds_max = np.max(csds,axis=0)\n",
    "ccvs_mu = np.mean(ccvs,axis=0)\n",
    "ccvs_min = np.min(ccvs,axis=0)\n",
    "ccvs_max = np.max(ccvs,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# baseline\n",
    "x = [1,2,3,4,5,6,7,8,9]\n",
    "rf = np.divide(1,np.square(x)) # 1/(x^2)\n",
    "d = np.sum(rf)\n",
    "f = np.divide(rf,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_hists(i_ind):\n",
    "    mumat = chist_mu[i_ind,:,0:9]\n",
    "    minmat = chist_min[i_ind,:,0:9]\n",
    "    maxmat = chist_max[i_ind,:,0:9]\n",
    "    fig, ax = plt.subplots(9,1,sharex=True, sharey=True,figsize=(5,10))\n",
    "    x = [1,2,3,4,5,6,7,8,9]\n",
    "    fig.tight_layout()\n",
    "    plt.xticks([1,2,3,4,5,6,7,8,9])\n",
    "    tstr = 'I = ' + str(iter_list[i_ind])\n",
    "    ax[0].set_title(tstr)\n",
    "    for i in range(9):\n",
    "        ax[i].plot(x,mumat[i,:],'k-')\n",
    "        ax[i].fill_between(x,minmat[i,:],maxmat[i,:], facecolor='orange')\n",
    "        ax[i].plot(x,f)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_one_hist(run,i_ind):\n",
    "    mumat = chist[run-1,i_ind,:,0:9]\n",
    "    fig, ax = plt.subplots(9,1,sharex=True, sharey=True,figsize=(5,10))\n",
    "    x = [1,2,3,4,5,6,7,8,9]\n",
    "    fig.tight_layout()\n",
    "    plt.xticks([1,2,3,4,5,6,7,8,9])\n",
    "    tstr = 'Run = ' + str(run) + ', Iter = ' + str(iter_list[i_ind])\n",
    "    ax[0].set_title(tstr)\n",
    "    for i in range(9):\n",
    "        ax[i].plot(x,mumat[i,:],'k-')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_one_hist(1,2) # Run =1, Iter = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hists(0) # All runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hists(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hists(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_hists(110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_stats(smu,smin,smax):\n",
    "    fig, ax = plt.subplots(num_iters, sharex=True, sharey=True,figsize=(5,70))\n",
    "    fig.tight_layout()\n",
    "    plt.xticks([1,2,3,4,5,6,7,8,9])\n",
    "    x = [1,2,3,4,5,6,7,8,9]\n",
    "    for i in range(num_iters):\n",
    "        tstr = 'I = ' + str(iter_list[i])\n",
    "        ax[i].set_title(tstr)\n",
    "        ax[i].plot(x,smu[i,:],'k-')\n",
    "        ax[i].fill_between(x,smin[i,:],smax[i,:], facecolor='orange')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_stats(cmus_mu,cmus_min,cmus_max) # mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_stats(csds_mu,csds_min,csds_max) # standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_stats(ccvs_mu,ccvs_min,ccvs_max) # cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# choice_avg: [num_iters, output_size, output_size]\n",
    "choice_hist = np.zeros([num_iters,10])\n",
    "for i in range (num_iters):\n",
    "    for j in range(10):\n",
    "        choice_hist[i,j] = choice_avg[i,j,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_choice_hists():\n",
    "    fig, ax = plt.subplots(9,1,sharex=True, sharey=True,figsize=(5,10))\n",
    "    x = [1,2,3,4,5,6,7,8,9]\n",
    "    fig.tight_layout()\n",
    "    plt.xticks([1,2,3,4,5,6,7,8,9])\n",
    "    #tstr = 'I = ' + str(iter_list[i_ind])\n",
    "    #ax[0].set_title(tstr)\n",
    "    for i in range(num_iters):\n",
    "        for j in range(10):\n",
    "            ax[j].plot(x,choice_hist[i,j],'k-')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "\n",
    "x = np.linspace(iter_list[0], iter_list[num_iters-1], num_iters)\n",
    "y = choice_hist[:,5]\n",
    "\n",
    "TOOLS = \"pan,wheel_zoom,box_zoom,reset,save,box_select\"\n",
    "\n",
    "p = figure(title=\"Another Legend Example\", tools=TOOLS)\n",
    "\n",
    "p.line(x, choice_hist[:,1], legend=\"1\",line_color=\"red\", line_width=3)\n",
    "p.line(x, choice_hist[:,2], legend=\"2\", line_color=\"orange\", line_width=3)\n",
    "p.line(x, choice_hist[:,3], legend=\"3\", line_color=\"yellow\", line_width=3)\n",
    "p.line(x, choice_hist[:,4], legend=\"4\", line_color=\"green\", line_width=3)\n",
    "p.line(x, choice_hist[:,5], legend=\"5\", line_color=\"blue\")\n",
    "p.line(x, choice_hist[:,6], legend=\"6\", line_color=\"purple\", line_width=3)\n",
    "p.line(x, choice_hist[:,7], legend=\"7\", line_color=\"olivedrab\", line_width=3)\n",
    "p.line(x, choice_hist[:,8], legend=\"8\", line_color=\"tomato\", line_width=3)\n",
    "p.line(x, choice_hist[:,9], legend=\"9\", line_color=\"gold\", line_width=3)\n",
    "p.xaxis.axis_label = \"Iterations\"\n",
    "p.yaxis.axis_label = \"Ave\"\n",
    "show(gridplot(p, ncols=2, plot_width=800, plot_height=800,title=\"legend.py example\"))  # open a browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
