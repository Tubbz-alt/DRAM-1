{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting everything up!\n"
     ]
    }
   ],
   "source": [
    "print(\"Setting everything up!\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from bokeh.io import push_notebook, show, output_notebook\n",
    "from bokeh.layouts import row, column\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models import ColumnDataSource, HoverTool, CustomJS, FixedTicker\n",
    "import bokeh.palettes as pal\n",
    "from bokeh.layouts import layout, Spacer, gridplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import *\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sychen23/.local/lib/python3.5/site-packages/bokeh/util/deprecation.py:34: BokehDeprecationWarning: \n",
      "The bokeh.charts API has moved to a separate 'bkcharts' package.\n",
      "\n",
      "This compatibility shim will remain until Bokeh 1.0 is released.\n",
      "After that, if you want to use this API you will have to install\n",
      "the bkcharts package explicitly.\n",
      "\n",
      "  warn(message)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from bokeh.charts import Bar, Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py', 'true', 'true', 'true', 'true', 'true', 'true', 'model_runs/regimen/classify_log.csv', 'model_runs/regimen/classifymodel_0.ckpt', 'model_runs/regimen/classifymodel_', 'model_runs/regimen/zzzdraw_data_5000.npy', 'false', 'true', 'false', 'false', 'true']\n",
      "analysis.py\n"
     ]
    }
   ],
   "source": [
    "from analysis import classify_image, glimpses, read_n, classify_imgs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import scipy.special\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "\n",
    "from scipy import linspace\n",
    "from scipy import pi,sqrt,exp\n",
    "from scipy.special import erf\n",
    "import scipy\n",
    "\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.plotting import figure, show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images: 10000\n",
      "INFO:tensorflow:Restoring parameters from model_runs/max_delta/classifymodel_10000.ckpt\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Key optimizer1/position/b/Adam not found in checkpoint\n\t [[Node: save/RestoreV2_20 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/RestoreV2_20/tensor_names, save/RestoreV2_20/shape_and_slices)]]\n\t [[Node: save/RestoreV2_235/_453 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_3106_save/RestoreV2_235\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\nCaused by op 'save/RestoreV2_20', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-75fb7cbb4cce>\", line 1, in <module>\n    from analysis import classify_image, glimpses, read_n, classify_imgs2\n  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 673, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 665, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\n  File \"/home/sychen23/DRAM/analysis.py\", line 24, in <module>\n    saver = tf.train.Saver()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 1056, in __init__\n    self.build()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 1086, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 691, in build\n    restore_sequentially, reshape)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 407, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 247, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 669, in restore_v2\n    dtypes=dtypes, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nNotFoundError (see above for traceback): Key optimizer1/position/b/Adam not found in checkpoint\n\t [[Node: save/RestoreV2_20 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/RestoreV2_20/tensor_names, save/RestoreV2_20/shape_and_slices)]]\n\t [[Node: save/RestoreV2_235/_453 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_3106_save/RestoreV2_235\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key optimizer1/position/b/Adam not found in checkpoint\n\t [[Node: save/RestoreV2_20 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/RestoreV2_20/tensor_names, save/RestoreV2_20/shape_and_slices)]]\n\t [[Node: save/RestoreV2_235/_453 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_3106_save/RestoreV2_235\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-508f521bcf25>\u001b[0m in \u001b[0;36mon_click2\u001b[0;34m(b2, new_image)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0mb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Loading...\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0mupdate_curves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m     \u001b[0mb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Next (Random) Image\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-508f521bcf25>\u001b[0m in \u001b[0;36mupdate_curves\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mnum_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"number of images: %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnum_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mimgs_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify_imgs2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropdown2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;31m#     num_blobs = randint(0, 9)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DRAM/analysis.py\u001b[0m in \u001b[0;36mclassify_imgs2\u001b[0;34m(it, new_imgs, num_imgs)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m     \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhuman\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0mhuman_cs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmachine_cs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifications\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DRAM/analysis.py\u001b[0m in \u001b[0;36mload_checkpoint\u001b[0;34m(it, human)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhuman\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"model_runs/max_delta\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%s/classifymodel_%d.ckpt\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Restoring parameters from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1457\u001b[0;31m              {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key optimizer1/position/b/Adam not found in checkpoint\n\t [[Node: save/RestoreV2_20 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/RestoreV2_20/tensor_names, save/RestoreV2_20/shape_and_slices)]]\n\t [[Node: save/RestoreV2_235/_453 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_3106_save/RestoreV2_235\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\nCaused by op 'save/RestoreV2_20', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-75fb7cbb4cce>\", line 1, in <module>\n    from analysis import classify_image, glimpses, read_n, classify_imgs2\n  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 673, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 665, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\n  File \"/home/sychen23/DRAM/analysis.py\", line 24, in <module>\n    saver = tf.train.Saver()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 1056, in __init__\n    self.build()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 1086, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 691, in build\n    restore_sequentially, reshape)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 407, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\", line 247, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 669, in restore_v2\n    dtypes=dtypes, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nNotFoundError (see above for traceback): Key optimizer1/position/b/Adam not found in checkpoint\n\t [[Node: save/RestoreV2_20 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/RestoreV2_20/tensor_names, save/RestoreV2_20/shape_and_slices)]]\n\t [[Node: save/RestoreV2_235/_453 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_3106_save/RestoreV2_235\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "clear_output()\n",
    "b2 = Button(description=\"Click to Start\", icon=\"arrow\", width=400)\n",
    "\n",
    "dropdown2 = Dropdown(options=['0', '1000', '2000', '3000', '4000', '5000', '10000', '20000', '30000', '40000', '50000',\n",
    "                             '60000', '70000', '80000', '90000', '100000', '110000', '120000', '130000', '140000', '150000',\n",
    "                             '160000', '170000', '180000', '190000', '200000', '250000', '300000', '400000', '500000',\n",
    "                             '600000', '700000', '800000', '900000', '910000', '920000', '1000000', '1100000', '1200000', '1300000', '1400000', '1500000'],\n",
    "                    value='10000', \n",
    "                    description='Iteration:'\n",
    ")\n",
    "\n",
    "data = None\n",
    "    \n",
    "    \n",
    "def get_pdf(sigma, x, mu):\n",
    "    \"\"\"Calculate the pdf.\"\"\"\n",
    "    \n",
    "#     pdf = 1/(x* sigma * np.sqrt(2*np.pi)) * np.exp(-(np.log(x)-mu)**2 / (2*sigma**2))\n",
    "    pdf = 1/(sigma * np.sqrt(2*np.pi)) * np.exp(-(x-mu)**2 / (2*sigma**2))\n",
    "    return pdf\n",
    "\n",
    "\n",
    "def get_cdf(sigma, x, mu, a):\n",
    "    \"\"\"Calculate the cdf.\"\"\"\n",
    "    \n",
    "#     cdf = (1 + erf(a*x / sqrt(2))) / 2 \n",
    "    cdf = (1 + scipy.special.erf((a*x - mu) / np.sqrt(2*sigma**2))) / 2\n",
    "    return cdf\n",
    "\n",
    "\n",
    "def get_p(pdf, cdf):\n",
    "    \"\"\"Calculate p to create skew curve.\"\"\"\n",
    "    \n",
    "    p = 2 / pdf * cdf / 100000\n",
    "    return p\n",
    "\n",
    "    \n",
    "def curve(sigma, x, mu, plot, label=\"\", color=\"gray\"):\n",
    "    \"\"\"Add normal distribution curve to plot.\"\"\"\n",
    "    \n",
    "    pdf = get_pdf(sigma, x, mu)\n",
    "    plot.line(x, pdf, line_color=color, line_width=8, alpha=1, legend=label)\n",
    "    \n",
    "    \n",
    "def skew_curve(sigma, x, mu, a, plot):\n",
    "    \"\"\"Add a skewed curve to the plot.\"\"\"\n",
    "    \n",
    "    p = get_p(get_pdf(sigma, x, mu), get_cdf(sigma, x, mu, a))\n",
    "\n",
    "    def f(x): return 1/(sigma * np.sqrt(2*np.pi)) * np.exp(-(x-mu)**2 / (2*sigma**2))\n",
    "    max_x = scipy.optimize.fmin(lambda x: -f(x), a)\n",
    "\n",
    "    plot.line(9-x, p / f(max_x), line_color=\"blue\", line_width=8, alpha=0.4)\n",
    "    \n",
    "    \n",
    "def combined_curve(sigma, x, mu, a, plot):\n",
    "    \"\"\"Add curve combining skew and normal distribution to plot.\"\"\"\n",
    "    \n",
    "    p = get_p(get_pdf(sigma, x, mu), get_cdf(sigma, x, mu, a))\n",
    "    \n",
    "    def f(x): return 1/(sigma * np.sqrt(2*np.pi)) * np.exp(-(x-mu)**2 / (2*sigma**2))\n",
    "    max_x = scipy.optimize.fmin(lambda x: -f(x), a)\n",
    "\n",
    "    def f2(x): return (1/(sigma * np.sqrt(2*np.pi)) * np.exp(-(x-mu)**2 / (2*sigma**2)) + p / f(max_x))\n",
    "    max_x2 = scipy.optimize.fmin(lambda x: -f(x), a)\n",
    "\n",
    "    plot.line(x, (((1/(sigma * np.sqrt(2*np.pi)) * np.exp(-(x-mu)**2 / (2*sigma**2)))\n",
    "            + p / f(max_x))/ f2(max_x2)), line_color=\"purple\", line_width=2, alpha=1)\n",
    "    \n",
    "\n",
    "def update_curves():\n",
    "    clear_output()\n",
    "    global data\n",
    "    num_imgs = 10000\n",
    "    print(\"number of images: %d\" % num_imgs)\n",
    "    imgs_data = classify_imgs2(int(dropdown2.value), True, num_imgs)\n",
    "    \n",
    "#     num_blobs = randint(0, 9)\n",
    "    max_blobs = 9\n",
    "    min_blobs = 0\n",
    "    \n",
    "    curves = list()\n",
    "    dark = \"#111111\"\n",
    "    light = \"#DDDDDD\"\n",
    "    p2 = figure(title=\"Blob Number Classification Probabilities Distributions\", y_range=(0, 1), tools=\"save\", background_fill_color=dark)\n",
    "    p2.border_fill_color = dark\n",
    "    p2.title.text_color = light\n",
    "    p2.xaxis.axis_label_text_color = light\n",
    "    p2.yaxis.axis_label_text_color = light\n",
    "    p2.xaxis.axis_line_color = light\n",
    "    p2.yaxis.axis_line_color = light\n",
    "    p2.xaxis.major_label_text_color = light\n",
    "    p2.yaxis.major_label_text_color = light\n",
    "    p2.xaxis.major_tick_line_color = light\n",
    "    p2.xaxis.minor_tick_line_color = light\n",
    "    p2.yaxis.major_tick_line_color = light\n",
    "    p2.yaxis.minor_tick_line_color = light\n",
    "\n",
    "    for num_blobs in range(min_blobs, max_blobs + 1):\n",
    "        print(\"num_blobs: \", num_blobs)\n",
    "        \n",
    "\n",
    "        p1 = figure(title=\"Blob Number Classification Probabilities Distribution for %d Blobs\" % num_blobs, y_range=(0, 1), tools=\"save\",\n",
    "                    background_fill_color=dark)\n",
    "        p1.border_fill_color = dark\n",
    "        p1.title.text_color = light\n",
    "        p1.xaxis.axis_label_text_color = light\n",
    "        p1.yaxis.axis_label_text_color = light\n",
    "        p1.xaxis.axis_line_color = light\n",
    "        p1.yaxis.axis_line_color = light\n",
    "        p1.xaxis.major_label_text_color = light\n",
    "        p1.yaxis.major_label_text_color = light\n",
    "        p1.xaxis.major_tick_line_color = light\n",
    "        p1.xaxis.minor_tick_line_color = light\n",
    "        p1.yaxis.major_tick_line_color = light\n",
    "        p1.yaxis.minor_tick_line_color = light\n",
    "\n",
    "\n",
    "\n",
    "        m = 0.1\n",
    "        z_size = 10\n",
    "\n",
    "        new_hist = np.zeros(z_size)\n",
    "        choice_hist = np.zeros(z_size)\n",
    "        value_counts = np.zeros(z_size)\n",
    "        values_sum = 0\n",
    "        sqr_sum = 0\n",
    "        num_imgs_with_num_blobs = 0\n",
    "\n",
    "        for idx, data in enumerate(imgs_data):\n",
    "\n",
    "            if data[\"label\"][num_blobs] == 1: # data is for an image with num_blobs blobs\n",
    "                num_imgs_with_num_blobs += 1\n",
    "                \n",
    "                max_glimpse = 2\n",
    "                min_glimpse = 0\n",
    "                glimpses = 5#max_glimpse - min_glimpse + 1\n",
    "                \n",
    "                for i in [0, 1, 2, 3, 4]:#range(min_glimpse, max_glimpse + 1):\n",
    "                    # Histogram of softmaxes\n",
    "                    new_hist += data[\"classifications\"][i][0] / glimpses\n",
    "                    \n",
    "                    # Histogram of choices\n",
    "                    choice = np.argmax(data[\"classifications\"][i][0])\n",
    "                    choice_list = [0] * z_size\n",
    "                    choice_list[choice] = 1 / glimpses\n",
    "                    choice_hist += choice_list\n",
    "                    \n",
    "#                 glimpse = 1\n",
    "        \n",
    "#                 new_hist += data[\"classifications\"][glimpse][0]\n",
    "        \n",
    "#                 choice = np.argmax(data[\"classifications\"][glimpse][0])\n",
    "#                 choice_list = [0] * z_size\n",
    "#                 choice_list[choice] = 1\n",
    "#                 choice_hist += choice_list\n",
    "                \n",
    "        print(\"num_imgs_with_num_blobs: \", num_imgs_with_num_blobs)\n",
    "        \n",
    "        new_hist = new_hist / num_imgs_with_num_blobs\n",
    "        print(\"new_hist: \", new_hist)\n",
    "        choice_hist = choice_hist / num_imgs_with_num_blobs\n",
    "\n",
    "        x = np.linspace(-2, 11.0, 1000)\n",
    "        source = ColumnDataSource(data=dict(color=[\"red\"] * z_size, top=new_hist, bottom=np.zeros(z_size), left=np.arange(z_size) + m - 0.55, right=np.arange(1, z_size + 1) - m - 0.55))\n",
    "        source2 = ColumnDataSource(data=dict(color=[\"yellow\"] * z_size, top=choice_hist, bottom=np.zeros(z_size), left=np.arange(z_size) + m - 0.45, right=np.arange(1, z_size + 1) - m - 0.45))\n",
    "        source.data[\"color\"][num_blobs] = \"lime\"\n",
    "        p1.quad('left', 'right', 'top', 'bottom', source=source, color=\"color\", alpha=1)\n",
    "        p1.quad('left', 'right', 'top', 'bottom', source=source2, color=\"color\", alpha=0.5)\n",
    "\n",
    "\n",
    "        # FORMAT PLOT ##############################\n",
    "\n",
    "        p1.xaxis.axis_label = 'Number of Blobs'\n",
    "        p1.yaxis.axis_label = 'Classification Probability'\n",
    "        p1.xaxis[0].ticker=FixedTicker(ticks=np.arange(z_size))\n",
    "        \n",
    "        \n",
    "        # PLOT CURVES #############################\n",
    "        \n",
    "        # Find the mean\n",
    "        for j in range(z_size):\n",
    "            values_sum += j * new_hist[j]\n",
    "        mu = values_sum\n",
    "        print(\"mu: \", mu)\n",
    "\n",
    "        # Find the standard deviation\n",
    "        for k in range(z_size):\n",
    "            sqr_sum += new_hist[k] * ((k - mu) ** 2)\n",
    "        sigma = np.sqrt(sqr_sum)\n",
    "        \n",
    "        curves.append((sigma * 2, x, mu, p2, str(num_blobs),\n",
    "                       \"#\" + str(randint(2, 9)) + str(randint(2, 9))+ str(randint(2, 9))+ str(randint(2, 9))+ str(randint(2, 9))+ str(randint(2, 9))))\n",
    "        \n",
    "        curve(sigma, x, mu, p1) # plot gaussian curve\n",
    "#         a = np.argmax(new_hist)\n",
    "#         skew_curve(sigma, x, mu, a, p1)\n",
    "#         combined_curve(sigma, x, mu, a, p1)\n",
    "\n",
    "        show(gridplot(p1, ncols=2, plot_width=500, plot_height=400, toolbar_location=None))\n",
    "    \n",
    "    for stats in curves:\n",
    "        curve(*stats)\n",
    "    show(p2)\n",
    "    \n",
    "\n",
    "def on_click2(b2, new_image=True):\n",
    "    \"\"\"Load new random image after button is clicked.\"\"\"\n",
    "    \n",
    "    b2.description = \"Loading...\"\n",
    "    update_curves()\n",
    "    b2.description = \"Next (Random) Image\"\n",
    "\n",
    "b2.on_click(on_click2)\n",
    "\n",
    "\n",
    "def on_change2(change):\n",
    "    \"\"\"Change the iteration number to new dropdown selection.\"\"\"\n",
    "    \n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        on_click(b2, new_image=False)\n",
    "        \n",
    "\n",
    "dropdown2.observe(on_change2)\n",
    "display(HBox([b2, dropdown2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
